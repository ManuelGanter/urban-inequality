{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b98aece",
   "metadata": {},
   "source": [
    "## Transfer testing scheme\n",
    "#### Option 1: Use all cities from both countries and predict one\n",
    "#### Option 2: Use the cities from the same country to predict city in country\n",
    "#### Option 3: Train a meta learner getting predictions of city models as input\n",
    "#### Option 4: Train one city model and predict all other cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a563f5",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from helper import get_training_data, get_csv_as_gpd, get_best_pca_lasso_model, get_best_lasso_model, train_xgboost\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336bf7c",
   "metadata": {},
   "source": [
    "## Generate master data set with all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3af094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data (344, 243)\n",
      "shape of training data (176, 243)\n",
      "shape of training data (861, 243)\n",
      "shape of training data (122, 243)\n",
      "shape of training data (125, 243)\n",
      "shape of training data (129, 243)\n",
      "(1757, 243)\n",
      "(1757, 243)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assigned_city</th>\n",
       "      <th>districts_admin_level_11_id</th>\n",
       "      <th>convenience_area_count_1000</th>\n",
       "      <th>camera_surveillance_area_count_1000</th>\n",
       "      <th>tourist_info_area_count_1000</th>\n",
       "      <th>attraction_area_count_1000</th>\n",
       "      <th>pharmacy_area_count_1000</th>\n",
       "      <th>post_box_area_count_1000</th>\n",
       "      <th>bank_area_count_1000</th>\n",
       "      <th>bakery_area_count_1000</th>\n",
       "      <th>...</th>\n",
       "      <th>jewish_min_dist</th>\n",
       "      <th>muslim_min_dist</th>\n",
       "      <th>christian_min_dist</th>\n",
       "      <th>buddhist_min_dist</th>\n",
       "      <th>dist_to_cc</th>\n",
       "      <th>foreign_nationals</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>income_levels</th>\n",
       "      <th>random_noise</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marseille</td>\n",
       "      <td>FR-official_id-130020106-admin_level-11</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.187919</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.810811</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.622222</td>\n",
       "      <td>...</td>\n",
       "      <td>2.841163</td>\n",
       "      <td>2.829058</td>\n",
       "      <td>0.903775</td>\n",
       "      <td>-0.176350</td>\n",
       "      <td>1.454689</td>\n",
       "      <td>-0.684105</td>\n",
       "      <td>-0.521390</td>\n",
       "      <td>1.029202</td>\n",
       "      <td>1.916586</td>\n",
       "      <td>POLYGON ((5.54771 43.34452, 5.54753 43.34451, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marseille</td>\n",
       "      <td>FR-official_id-130050702-admin_level-11</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.161074</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.642857</td>\n",
       "      <td>-0.756757</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.198778</td>\n",
       "      <td>4.817203</td>\n",
       "      <td>1.997066</td>\n",
       "      <td>0.033113</td>\n",
       "      <td>2.122303</td>\n",
       "      <td>-0.669459</td>\n",
       "      <td>-0.619313</td>\n",
       "      <td>1.074703</td>\n",
       "      <td>2.538804</td>\n",
       "      <td>POLYGON ((5.51860 43.28693, 5.51839 43.28692, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marseille</td>\n",
       "      <td>FR-official_id-130710105-admin_level-11</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.080537</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-0.864865</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-0.355556</td>\n",
       "      <td>...</td>\n",
       "      <td>3.466202</td>\n",
       "      <td>0.986584</td>\n",
       "      <td>1.253323</td>\n",
       "      <td>-1.716229</td>\n",
       "      <td>1.267491</td>\n",
       "      <td>-0.703629</td>\n",
       "      <td>-0.573965</td>\n",
       "      <td>0.504457</td>\n",
       "      <td>3.436804</td>\n",
       "      <td>POLYGON ((5.35367 43.37689, 5.35352 43.37659, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marseille</td>\n",
       "      <td>FR-official_id-130750102-admin_level-11</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.107383</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>-0.108108</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>1.389558</td>\n",
       "      <td>1.039531</td>\n",
       "      <td>0.382529</td>\n",
       "      <td>0.341271</td>\n",
       "      <td>0.925596</td>\n",
       "      <td>-0.676339</td>\n",
       "      <td>-0.598862</td>\n",
       "      <td>0.612597</td>\n",
       "      <td>2.055997</td>\n",
       "      <td>POLYGON ((5.47010 43.34248, 5.47001 43.34236, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marseille</td>\n",
       "      <td>FR-official_id-130750104-admin_level-11</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.187919</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.324324</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>2.477888</td>\n",
       "      <td>2.057345</td>\n",
       "      <td>2.331364</td>\n",
       "      <td>0.880692</td>\n",
       "      <td>1.379049</td>\n",
       "      <td>-0.691519</td>\n",
       "      <td>-0.454218</td>\n",
       "      <td>0.928744</td>\n",
       "      <td>1.661400</td>\n",
       "      <td>POLYGON ((5.46373 43.34745, 5.46349 43.34758, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>bremen</td>\n",
       "      <td>DE-official_id-04012000021-admin_level-11</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.470588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231711</td>\n",
       "      <td>0.428310</td>\n",
       "      <td>1.972046</td>\n",
       "      <td>1.890189</td>\n",
       "      <td>1.928484</td>\n",
       "      <td>-0.230593</td>\n",
       "      <td>0.339796</td>\n",
       "      <td>0.320310</td>\n",
       "      <td>-0.059541</td>\n",
       "      <td>POLYGON ((8.63110 53.55557, 8.63111 53.55555, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>bremen</td>\n",
       "      <td>DE-official_id-04012000022-admin_level-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.352941</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.741527</td>\n",
       "      <td>0.497816</td>\n",
       "      <td>0.866531</td>\n",
       "      <td>2.180809</td>\n",
       "      <td>2.220471</td>\n",
       "      <td>-0.648528</td>\n",
       "      <td>0.037946</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>2.279603</td>\n",
       "      <td>POLYGON ((8.59095 53.59348, 8.59097 53.59336, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>bremen</td>\n",
       "      <td>DE-official_id-04012000023-admin_level-11</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.470588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570909</td>\n",
       "      <td>0.510213</td>\n",
       "      <td>-0.230222</td>\n",
       "      <td>1.836003</td>\n",
       "      <td>1.873291</td>\n",
       "      <td>-0.565739</td>\n",
       "      <td>0.610655</td>\n",
       "      <td>-0.051318</td>\n",
       "      <td>2.660508</td>\n",
       "      <td>POLYGON ((8.63762 53.50365, 8.63758 53.50363, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>bremen</td>\n",
       "      <td>DE-official_id-04012000024-admin_level-11</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720531</td>\n",
       "      <td>-0.654242</td>\n",
       "      <td>-0.060436</td>\n",
       "      <td>2.079863</td>\n",
       "      <td>2.117092</td>\n",
       "      <td>0.881500</td>\n",
       "      <td>1.951820</td>\n",
       "      <td>-1.320075</td>\n",
       "      <td>1.193018</td>\n",
       "      <td>POLYGON ((8.58696 53.56894, 8.58672 53.56694, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>bremen</td>\n",
       "      <td>DE-official_id-04012000025-admin_level-11</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.529412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228877</td>\n",
       "      <td>2.152288</td>\n",
       "      <td>0.336473</td>\n",
       "      <td>2.294835</td>\n",
       "      <td>2.332764</td>\n",
       "      <td>-0.735236</td>\n",
       "      <td>0.185183</td>\n",
       "      <td>0.431168</td>\n",
       "      <td>0.402068</td>\n",
       "      <td>POLYGON ((8.54787 53.60448, 8.54865 53.60432, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1757 rows Ã— 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     assigned_city                districts_admin_level_11_id  \\\n",
       "0        marseille    FR-official_id-130020106-admin_level-11   \n",
       "1        marseille    FR-official_id-130050702-admin_level-11   \n",
       "2        marseille    FR-official_id-130710105-admin_level-11   \n",
       "3        marseille    FR-official_id-130750102-admin_level-11   \n",
       "4        marseille    FR-official_id-130750104-admin_level-11   \n",
       "...            ...                                        ...   \n",
       "1752        bremen  DE-official_id-04012000021-admin_level-11   \n",
       "1753        bremen  DE-official_id-04012000022-admin_level-11   \n",
       "1754        bremen  DE-official_id-04012000023-admin_level-11   \n",
       "1755        bremen  DE-official_id-04012000024-admin_level-11   \n",
       "1756        bremen  DE-official_id-04012000025-admin_level-11   \n",
       "\n",
       "      convenience_area_count_1000  camera_surveillance_area_count_1000  \\\n",
       "0                       -0.444444                            -0.187919   \n",
       "1                       -0.333333                            -0.161074   \n",
       "2                       -0.333333                            -0.080537   \n",
       "3                       -0.444444                            -0.107383   \n",
       "4                       -0.444444                            -0.187919   \n",
       "...                           ...                                  ...   \n",
       "1752                    -0.333333                             0.000000   \n",
       "1753                     0.000000                             3.000000   \n",
       "1754                    -0.333333                             0.000000   \n",
       "1755                     0.333333                             0.000000   \n",
       "1756                    -0.333333                             0.000000   \n",
       "\n",
       "      tourist_info_area_count_1000  attraction_area_count_1000  \\\n",
       "0                        -0.300000                         0.0   \n",
       "1                         0.200000                         0.0   \n",
       "2                        -0.200000                         0.0   \n",
       "3                        -0.400000                         0.0   \n",
       "4                        -0.400000                         0.0   \n",
       "...                            ...                         ...   \n",
       "1752                     -0.470588                         0.0   \n",
       "1753                     -0.352941                         3.0   \n",
       "1754                     -0.470588                         0.0   \n",
       "1755                      0.000000                         0.0   \n",
       "1756                     -0.529412                         0.0   \n",
       "\n",
       "      pharmacy_area_count_1000  post_box_area_count_1000  \\\n",
       "0                    -0.571429                 -0.810811   \n",
       "1                    -0.642857                 -0.756757   \n",
       "2                    -0.285714                 -0.864865   \n",
       "3                    -0.428571                 -0.108108   \n",
       "4                    -0.571429                 -0.324324   \n",
       "...                        ...                       ...   \n",
       "1752                 -0.500000                 -0.571429   \n",
       "1753                 -0.500000                 -0.428571   \n",
       "1754                 -1.000000                 -0.714286   \n",
       "1755                  1.000000                  0.000000   \n",
       "1756                 -1.000000                 -0.714286   \n",
       "\n",
       "      bank_area_count_1000  bakery_area_count_1000  ...  jewish_min_dist  \\\n",
       "0                -0.444444               -0.622222  ...         2.841163   \n",
       "1                -0.444444               -0.533333  ...         4.198778   \n",
       "2                -0.111111               -0.355556  ...         3.466202   \n",
       "3                -0.333333               -0.444444  ...         1.389558   \n",
       "4                -0.444444               -0.444444  ...         2.477888   \n",
       "...                    ...                     ...  ...              ...   \n",
       "1752             -0.500000               -0.166667  ...         0.231711   \n",
       "1753              0.000000               -0.500000  ...        -0.741527   \n",
       "1754             -0.500000               -0.500000  ...         0.570909   \n",
       "1755              0.500000                0.333333  ...        -0.720531   \n",
       "1756             -0.500000               -0.666667  ...         0.228877   \n",
       "\n",
       "      muslim_min_dist  christian_min_dist  buddhist_min_dist  dist_to_cc  \\\n",
       "0            2.829058            0.903775          -0.176350    1.454689   \n",
       "1            4.817203            1.997066           0.033113    2.122303   \n",
       "2            0.986584            1.253323          -1.716229    1.267491   \n",
       "3            1.039531            0.382529           0.341271    0.925596   \n",
       "4            2.057345            2.331364           0.880692    1.379049   \n",
       "...               ...                 ...                ...         ...   \n",
       "1752         0.428310            1.972046           1.890189    1.928484   \n",
       "1753         0.497816            0.866531           2.180809    2.220471   \n",
       "1754         0.510213           -0.230222           1.836003    1.873291   \n",
       "1755        -0.654242           -0.060436           2.079863    2.117092   \n",
       "1756         2.152288            0.336473           2.294835    2.332764   \n",
       "\n",
       "      foreign_nationals  unemployment_rate  income_levels  random_noise  \\\n",
       "0             -0.684105          -0.521390       1.029202      1.916586   \n",
       "1             -0.669459          -0.619313       1.074703      2.538804   \n",
       "2             -0.703629          -0.573965       0.504457      3.436804   \n",
       "3             -0.676339          -0.598862       0.612597      2.055997   \n",
       "4             -0.691519          -0.454218       0.928744      1.661400   \n",
       "...                 ...                ...            ...           ...   \n",
       "1752          -0.230593           0.339796       0.320310     -0.059541   \n",
       "1753          -0.648528           0.037946       0.463917      2.279603   \n",
       "1754          -0.565739           0.610655      -0.051318      2.660508   \n",
       "1755           0.881500           1.951820      -1.320075      1.193018   \n",
       "1756          -0.735236           0.185183       0.431168      0.402068   \n",
       "\n",
       "                                               geometry  \n",
       "0     POLYGON ((5.54771 43.34452, 5.54753 43.34451, ...  \n",
       "1     POLYGON ((5.51860 43.28693, 5.51839 43.28692, ...  \n",
       "2     POLYGON ((5.35367 43.37689, 5.35352 43.37659, ...  \n",
       "3     POLYGON ((5.47010 43.34248, 5.47001 43.34236, ...  \n",
       "4     POLYGON ((5.46373 43.34745, 5.46349 43.34758, ...  \n",
       "...                                                 ...  \n",
       "1752  POLYGON ((8.63110 53.55557, 8.63111 53.55555, ...  \n",
       "1753  POLYGON ((8.59095 53.59348, 8.59097 53.59336, ...  \n",
       "1754  POLYGON ((8.63762 53.50365, 8.63758 53.50363, ...  \n",
       "1755  POLYGON ((8.58696 53.56894, 8.58672 53.56694, ...  \n",
       "1756  POLYGON ((8.54787 53.60448, 8.54865 53.60432, ...  \n",
       "\n",
       "[1757 rows x 243 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate dataset with all cities\n",
    "cities_fr = ['marseille', 'lyon', 'paris']\n",
    "cities_de = ['berlin', 'hamburg', 'bremen']\n",
    "\n",
    "agg_full = pd.DataFrame()\n",
    "\n",
    "#load all cities in cities_fr list\n",
    "if (len(cities_fr) !=0):\n",
    "    for city in cities_fr:\n",
    "        #load data\n",
    "        agg = get_training_data(city, 'FR', 1000, 'count', 2015)\n",
    "        agg_full = agg_full.append(agg)\n",
    "#load all cities in cities_de list        \n",
    "if (len(cities_de) !=0):\n",
    "    for city in cities_de:\n",
    "        #load data\n",
    "        agg = get_training_data(city, 'DE', 1000, 'count', 2015)\n",
    "        agg_full = agg_full.append(agg)\n",
    "    \n",
    "print(agg_full.shape)\n",
    "agg_full=agg_full.dropna(axis = 1)\n",
    "agg_full = agg_full.reset_index(drop = True)\n",
    "print(agg_full.shape)\n",
    "agg_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6f0659",
   "metadata": {},
   "source": [
    "### Leave-one-city-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9dc1588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes\n",
    "loo_results_impr = pd.DataFrame(columns = ['unemployment_rate', 'foreign_nationals', 'income_levels'])\n",
    "loo_results_r2_score = pd.DataFrame(columns = ['unemployment_rate', 'foreign_nationals', 'income_levels'])\n",
    "full_residuals_unemployment = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "full_residuals_income = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "full_residuals_fn = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026e5c23",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f93b597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (1413, 236)\n",
      "number of pca components: 173\n",
      "shape after pca: (1413, 173)\n",
      "0.1\n",
      "shape before pca: (1413, 236)\n",
      "number of pca components: 173\n",
      "shape after pca: (1413, 173)\n",
      "0.1\n",
      "shape before pca: (1581, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1581, 169)\n",
      "0.2\n",
      "shape before pca: (1581, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1581, 169)\n",
      "0.2\n",
      "shape before pca: (896, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (896, 146)\n",
      "0.01\n",
      "shape before pca: (896, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (896, 146)\n",
      "0.01\n",
      "shape before pca: (1635, 236)\n",
      "number of pca components: 167\n",
      "shape after pca: (1635, 167)\n",
      "0.1\n",
      "shape before pca: (1635, 236)\n",
      "number of pca components: 167\n",
      "shape after pca: (1635, 167)\n",
      "0.1\n",
      "shape before pca: (1632, 236)\n",
      "number of pca components: 171\n",
      "shape after pca: (1632, 171)\n",
      "0.1\n",
      "shape before pca: (1632, 236)\n",
      "number of pca components: 171\n",
      "shape after pca: (1632, 171)\n",
      "0.1\n",
      "shape before pca: (1628, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1628, 169)\n",
      "0.1\n",
      "shape before pca: (1628, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1628, 169)\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "for city in ['marseille', 'lyon', 'paris']: \n",
    "    \n",
    "    #set target and city\n",
    "    country = 'FR'\n",
    "    target = 'unemployment_rate'\n",
    "    target_city = city\n",
    "    \n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full[agg_full.assigned_city!=target_city]\n",
    "    test = agg_full[agg_full.assigned_city==target_city]\n",
    "    \n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights\n",
    "    \n",
    "    #split data in x and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True) \n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    \n",
    "    #get selected columns\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    #train xgboost on subset\n",
    "    boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #fit pca and reduce dataset\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    \n",
    "    #train lasso regression\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get lasso chosen pca components and train xgboost\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier', learner_type = 'transfer', weights = weights_train)\n",
    "    \n",
    "    #apply pca to testset and make predictions\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    \n",
    "    # compute M5 prediction based on mean\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    #generate naive prediction\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    loo_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    loo_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.unemployment_rate-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.unemployment_rate-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_unemployment = pd.concat([full_residuals_unemployment, residuals])\n",
    "\n",
    "for city in ['berlin', 'hamburg', 'bremen']:\n",
    "    \n",
    "    #set target city and country\n",
    "    country = 'DE'\n",
    "    target_city = city\n",
    "    \n",
    "    #create train test split based on leaft-out city\n",
    "    train = agg_full[agg_full.assigned_city!=target_city]\n",
    "    test = agg_full[agg_full.assigned_city==target_city]\n",
    "\n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights    \n",
    "    \n",
    "    #split data in x and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True) \n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    #get lasso selected features and train xgboost on subset\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #apply base and reduce data\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    #train lasso regression on pca components\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get lasso selcted pca components and train xgboost\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    \n",
    "    #apply pca to testset\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    #make prediction \n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    # create naive predictions\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    loo_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    loo_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "\n",
    "    #compute residuals \n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.unemployment_rate-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.unemployment_rate-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_unemployment = pd.concat([full_residuals_unemployment, residuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ce7fb7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (1413, 236)\n",
      "number of pca components: 173\n",
      "shape after pca: (1413, 173)\n",
      "0.01\n",
      "shape before pca: (1413, 236)\n",
      "number of pca components: 173\n",
      "shape after pca: (1413, 173)\n",
      "0.01\n",
      "shape before pca: (1581, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1581, 169)\n",
      "0.1\n",
      "shape before pca: (1581, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1581, 169)\n",
      "0.1\n",
      "shape before pca: (896, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (896, 146)\n",
      "0.01\n",
      "shape before pca: (896, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (896, 146)\n",
      "0.01\n",
      "shape before pca: (1635, 236)\n",
      "number of pca components: 167\n",
      "shape after pca: (1635, 167)\n",
      "0.1\n",
      "shape before pca: (1635, 236)\n",
      "number of pca components: 167\n",
      "shape after pca: (1635, 167)\n",
      "0.1\n",
      "shape before pca: (1632, 236)\n",
      "number of pca components: 171\n",
      "shape after pca: (1632, 171)\n",
      "0.1\n",
      "shape before pca: (1632, 236)\n",
      "number of pca components: 171\n",
      "shape after pca: (1632, 171)\n",
      "0.1\n",
      "shape before pca: (1628, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1628, 169)\n",
      "0.2\n",
      "shape before pca: (1628, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1628, 169)\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "for city in ['marseille', 'lyon', 'paris']: \n",
    "\n",
    "    #set target and city\n",
    "    country = 'FR'\n",
    "    target = 'income_levels'\n",
    "    target_city = city\n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full[agg_full.assigned_city!=target_city]\n",
    "    test = agg_full[agg_full.assigned_city==target_city]\n",
    "   \n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights\n",
    "    \n",
    "    #split in x and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True) \n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    # get selected lasso features and train xgboost\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #fit and apply pca to trainset\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    #train lasso on pca components\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    # get lasso selected pca components\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier', learner_type = 'transfer', weights = weights_train)\n",
    "    \n",
    "    #apply pca to testset and predict\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    \n",
    "    #get prediction for M5\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    #get naive prediction\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    loo_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    loo_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.income_levels-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.income_levels-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_income = pd.concat([full_residuals_income, residuals])\n",
    "    \n",
    "for city in ['berlin', 'hamburg', 'bremen']:\n",
    "    # set target city\n",
    "    country = 'DE'\n",
    "    target_city = city\n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full[agg_full.assigned_city!=target_city]\n",
    "    test = agg_full[agg_full.assigned_city==target_city]\n",
    "    \n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights    \n",
    "    #split data in x and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True) \n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    # get selected lasso features and train xgboost\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #apply pca to trainset\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    \n",
    "    #train lasso regression on reduced data\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get lasso chosen pca components\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    \n",
    "    #apply pca to testset\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    \n",
    "    #et prediction for M5\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    #compute naive predictions\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    loo_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    loo_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.income_levels-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.income_levels-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_income = pd.concat([full_residuals_income, residuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f815dbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (1413, 236)\n",
      "number of pca components: 173\n",
      "shape after pca: (1413, 173)\n",
      "0.01\n",
      "shape before pca: (1413, 236)\n",
      "number of pca components: 173\n",
      "shape after pca: (1413, 173)\n",
      "0.01\n",
      "shape before pca: (1581, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1581, 169)\n",
      "0.2\n",
      "shape before pca: (1581, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1581, 169)\n",
      "0.2\n",
      "shape before pca: (896, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (896, 146)\n",
      "0.01\n",
      "shape before pca: (896, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (896, 146)\n",
      "0.01\n",
      "shape before pca: (1635, 236)\n",
      "number of pca components: 167\n",
      "shape after pca: (1635, 167)\n",
      "0.1\n",
      "shape before pca: (1635, 236)\n",
      "number of pca components: 167\n",
      "shape after pca: (1635, 167)\n",
      "0.1\n",
      "shape before pca: (1632, 236)\n",
      "number of pca components: 171\n",
      "shape after pca: (1632, 171)\n",
      "0.5\n",
      "shape before pca: (1632, 236)\n",
      "number of pca components: 171\n",
      "shape after pca: (1632, 171)\n",
      "0.5\n",
      "shape before pca: (1628, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1628, 169)\n",
      "0.5\n",
      "shape before pca: (1628, 236)\n",
      "number of pca components: 169\n",
      "shape after pca: (1628, 169)\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "for city in ['marseille', 'lyon', 'paris']: \n",
    "    #set target city and target variable\n",
    "    country = 'FR'\n",
    "    target = 'foreign_nationals'\n",
    "    target_city = city\n",
    "    \n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full[agg_full.assigned_city!=target_city]\n",
    "    test = agg_full[agg_full.assigned_city==target_city]\n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights\n",
    "    \n",
    "    #split data in x and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True)\n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    # get lasso selected features and train xgboost\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #apply pca to trainset\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    #train lasso regression on pca componetns\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5,6,7,8,9,10]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get lasso selected pca components\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier', learner_type = 'transfer', weights = weights_train)\n",
    "    \n",
    "    #apply pca to testset and make prediction\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    #get prediction of mean model\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    #compute naive prediction\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    loo_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    loo_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.foreign_nationals-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.foreign_nationals-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_fn = pd.concat([full_residuals_fn, residuals])\n",
    "    \n",
    "for city in ['berlin', 'hamburg', 'bremen']:\n",
    "    #set target city\n",
    "    country = 'DE'\n",
    "    target_city = city\n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full[agg_full.assigned_city!=target_city]\n",
    "    test = agg_full[agg_full.assigned_city==target_city]\n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights    \n",
    "    \n",
    "    #split data in x and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True)\n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    #get lasso selected columns and make predictions\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #apply pca to trainset\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    #train lasso regression on pca components\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5,6,7,8,9,10]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get lasso selected pca components\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    #apply lasso to testset and make predictions\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    \n",
    "    #make M5 prediction\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "    \n",
    "    #compute naive prediction\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    loo_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    loo_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.foreign_nationals-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.foreign_nationals-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_fn = pd.concat([full_residuals_fn, residuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2838d1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>foreign_nationals</th>\n",
       "      <th>income_levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>25.676754</td>\n",
       "      <td>31.633758</td>\n",
       "      <td>19.183957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>0.048349</td>\n",
       "      <td>-1.309613</td>\n",
       "      <td>-6.150607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>13.251059</td>\n",
       "      <td>13.005593</td>\n",
       "      <td>9.975073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>40.128826</td>\n",
       "      <td>33.333416</td>\n",
       "      <td>20.37572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>39.076534</td>\n",
       "      <td>19.465109</td>\n",
       "      <td>20.52393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>25.784639</td>\n",
       "      <td>5.899169</td>\n",
       "      <td>15.773473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.99436</td>\n",
       "      <td>17.004572</td>\n",
       "      <td>13.280258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unemployment_rate foreign_nationals income_levels\n",
       "marseille         25.676754         31.633758     19.183957\n",
       "lyon               0.048349         -1.309613     -6.150607\n",
       "paris             13.251059         13.005593      9.975073\n",
       "berlin            40.128826         33.333416      20.37572\n",
       "hamburg           39.076534         19.465109      20.52393\n",
       "bremen            25.784639          5.899169     15.773473\n",
       "mean               23.99436         17.004572     13.280258"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo_results_impr.loc['mean'] = loo_results_impr.mean()\n",
    "loo_results_impr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12d6ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>foreign_nationals</th>\n",
       "      <th>income_levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>0.245659</td>\n",
       "      <td>0.302784</td>\n",
       "      <td>0.191492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>-0.004347</td>\n",
       "      <td>-0.013445</td>\n",
       "      <td>-0.063776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>0.127158</td>\n",
       "      <td>0.119054</td>\n",
       "      <td>0.099139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>0.336146</td>\n",
       "      <td>0.320267</td>\n",
       "      <td>0.201038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>0.325853</td>\n",
       "      <td>0.19186</td>\n",
       "      <td>0.20353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>0.228731</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.131206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.209867</td>\n",
       "      <td>0.155042</td>\n",
       "      <td>0.127105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unemployment_rate foreign_nationals income_levels\n",
       "marseille          0.245659          0.302784      0.191492\n",
       "lyon              -0.004347         -0.013445     -0.063776\n",
       "paris              0.127158          0.119054      0.099139\n",
       "berlin             0.336146          0.320267      0.201038\n",
       "hamburg            0.325853           0.19186       0.20353\n",
       "bremen             0.228731          0.009735      0.131206\n",
       "mean               0.209867          0.155042      0.127105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo_results_r2_score.loc['mean'] = loo_results_r2_score.mean()\n",
    "loo_results_r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5f9723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTest: t=2.5451136095572804, p=0.01096663558897814\n"
     ]
    }
   ],
   "source": [
    "#TTest unemployment residuals\n",
    "t_stat, p = stats.ttest_ind(full_residuals_unemployment['residuals_naive'], full_residuals_unemployment['residuals_m5'])\n",
    "print(f'TTest: t={t_stat}, p={p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22af69a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTest: t=2.1952284341199224, p=0.028212430401222476\n"
     ]
    }
   ],
   "source": [
    "#TTest income residuals\n",
    "t_stat, p = stats.ttest_ind(full_residuals_income['residuals_naive'], full_residuals_income['residuals_m5'])\n",
    "print(f'TTest: t={t_stat}, p={p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca8c7162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTest: t=2.576098193401887, p=0.010032728721579526\n"
     ]
    }
   ],
   "source": [
    "#TTest foreign national residuals\n",
    "t_stat, p = stats.ttest_ind(full_residuals_fn['residuals_naive'], full_residuals_fn['residuals_m5'])\n",
    "print(f'TTest: t={t_stat}, p={p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79dcc25",
   "metadata": {},
   "source": [
    "### Leave-one-city-in-country-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9cb14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframes\n",
    "locico_results_impr = pd.DataFrame(columns = ['unemployment_rate', 'foreign_nationals', 'income_levels'])\n",
    "locico_results_r2_score = pd.DataFrame(columns = ['unemployment_rate', 'foreign_nationals', 'income_levels'])\n",
    "full_residuals_unemployment = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "full_residuals_income = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "full_residuals_fn = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7bc98d",
   "metadata": {},
   "source": [
    "### France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750808c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1757, 243)\n",
      "(1381, 243)\n"
     ]
    }
   ],
   "source": [
    "#get subset of french cities\n",
    "print(agg_full.shape)\n",
    "agg_full_fr = agg_full[agg_full.assigned_city.isin(['marseille', 'lyon', 'paris'])]\n",
    "print(agg_full_fr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5621b610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (1037, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (1037, 146)\n",
      "0.1\n",
      "shape before pca: (1037, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (1037, 146)\n",
      "0.1\n",
      "shape before pca: (1205, 236)\n",
      "number of pca components: 144\n",
      "shape after pca: (1205, 144)\n",
      "0.2\n",
      "shape before pca: (1205, 236)\n",
      "number of pca components: 144\n",
      "shape after pca: (1205, 144)\n",
      "0.2\n",
      "shape before pca: (520, 236)\n",
      "number of pca components: 98\n",
      "shape after pca: (520, 98)\n",
      "0.01\n",
      "shape before pca: (520, 236)\n",
      "number of pca components: 98\n",
      "shape after pca: (520, 98)\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "for city in ['marseille', 'lyon', 'paris']: \n",
    "    #set tartet variable and city\n",
    "    country = 'FR'\n",
    "    target = 'unemployment_rate'\n",
    "    target_city = city\n",
    "    \n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full_fr[agg_full_fr.assigned_city!=target_city]\n",
    "    test = agg_full_fr[agg_full_fr.assigned_city==target_city]\n",
    "    \n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights\n",
    "\n",
    "    #split data in x,y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True) \n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    # get lasso selected columns and make predictions\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    if (len(cols_lasso)==0):\n",
    "        boosted_lasso_predicts = clf1.predict(X_test)\n",
    "    else:\n",
    "        boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "        boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #apply pca to trainset\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    #train lasso regression on pca componetns\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get selected pca components and train xgboost\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    #apply pca on testset and make predictions\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    #get prediction for M5\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    #get naive predictions\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    locico_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    locico_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.unemployment_rate-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.unemployment_rate-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_unemployment = pd.concat([full_residuals_unemployment, residuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20d99b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (1037, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (1037, 146)\n",
      "0.01\n",
      "shape before pca: (1037, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (1037, 146)\n",
      "0.01\n",
      "shape before pca: (1205, 236)\n",
      "number of pca components: 144\n",
      "shape after pca: (1205, 144)\n",
      "0.1\n",
      "shape before pca: (1205, 236)\n",
      "number of pca components: 144\n",
      "shape after pca: (1205, 144)\n",
      "0.1\n",
      "shape before pca: (520, 236)\n",
      "number of pca components: 98\n",
      "shape after pca: (520, 98)\n",
      "0.01\n",
      "shape before pca: (520, 236)\n",
      "number of pca components: 98\n",
      "shape after pca: (520, 98)\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "for city in ['marseille', 'lyon', 'paris']: \n",
    "    #set target variable and city\n",
    "    country = 'FR'\n",
    "    target = 'income_levels'\n",
    "    target_city = city\n",
    "    \n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full_fr[agg_full_fr.assigned_city!=target_city]\n",
    "    test = agg_full_fr[agg_full_fr.assigned_city==target_city]\n",
    "    \n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights\n",
    "\n",
    "    #split data in X and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True) \n",
    "    \n",
    "    #train lasso regression\n",
    "    alphas = [ 0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    \n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    if (len(cols_lasso)==0):\n",
    "        boosted_lasso_predicts = clf1.predict(X_test)\n",
    "    else:\n",
    "        boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "        boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #apply pca to trainset\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    \n",
    "    #train lasso on pca components\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get lasso chosen pca components and train xgboost\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    #apply pca to testset\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    #get prediction for M5\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    #get naive prediction\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    locico_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    locico_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.income_levels-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.income_levels-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_income = pd.concat([full_residuals_income, residuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f28669dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (1037, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (1037, 146)\n",
      "0.01\n",
      "shape before pca: (1037, 236)\n",
      "number of pca components: 146\n",
      "shape after pca: (1037, 146)\n",
      "0.01\n",
      "shape before pca: (1205, 236)\n",
      "number of pca components: 144\n",
      "shape after pca: (1205, 144)\n",
      "0.2\n",
      "shape before pca: (1205, 236)\n",
      "number of pca components: 144\n",
      "shape after pca: (1205, 144)\n",
      "0.2\n",
      "shape before pca: (520, 236)\n",
      "number of pca components: 98\n",
      "shape after pca: (520, 98)\n",
      "0.01\n",
      "shape before pca: (520, 236)\n",
      "number of pca components: 98\n",
      "shape after pca: (520, 98)\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "for city in ['marseille', 'lyon', 'paris']: \n",
    "    #set target variable and city\n",
    "    country = 'FR'\n",
    "    target = 'foreign_nationals'\n",
    "    target_city = city\n",
    "    \n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full_fr[agg_full_fr.assigned_city!=target_city]\n",
    "    test = agg_full_fr[agg_full_fr.assigned_city==target_city]\n",
    "    \n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each citycity]\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights\n",
    "    #split data in x and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True) \n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    # get selected lasso features and train xgboost\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #apply pca on trainset\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    #train lasso on pca components\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get lasso selected pca components and train xgboost\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "   \n",
    "    #apply pca on testset and make predictions\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    #make prediction for M5\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    #get naive predictions\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    locico_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    locico_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.foreign_nationals-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.foreign_nationals-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_fn = pd.concat([full_residuals_fn, residuals])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefce552",
   "metadata": {},
   "source": [
    "### germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbaba727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1757, 243)\n",
      "(376, 243)\n"
     ]
    }
   ],
   "source": [
    "#get data subset for german cities\n",
    "print(agg_full.shape)\n",
    "agg_full_de = agg_full[agg_full.assigned_city.isin(['berlin', 'hamburg', 'bremen'])]\n",
    "print(agg_full_de.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45e2a874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (254, 236)\n",
      "number of pca components: 91\n",
      "shape after pca: (254, 91)\n",
      "0.1\n",
      "shape before pca: (254, 236)\n",
      "number of pca components: 91\n",
      "shape after pca: (254, 91)\n",
      "0.1\n",
      "shape before pca: (251, 236)\n",
      "number of pca components: 106\n",
      "shape after pca: (251, 106)\n",
      "0.1\n",
      "shape before pca: (251, 236)\n",
      "number of pca components: 106\n",
      "shape after pca: (251, 106)\n",
      "0.1\n",
      "shape before pca: (247, 236)\n",
      "number of pca components: 95\n",
      "shape after pca: (247, 95)\n",
      "0.1\n",
      "shape before pca: (247, 236)\n",
      "number of pca components: 95\n",
      "shape after pca: (247, 95)\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "target = 'unemployment_rate'\n",
    "for city in ['berlin', 'hamburg', 'bremen']: \n",
    "    \n",
    "    #set target city\n",
    "    country = 'DE'\n",
    "    target_city = city\n",
    "    \n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full_de[agg_full_de.assigned_city!=target_city]\n",
    "    test = agg_full_de[agg_full_de.assigned_city==target_city]\n",
    "    \n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights\n",
    "\n",
    "    #split in x and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True)\n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    #get lasso selected features and train xgboost\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #apply pca to trainset\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    #train lasso regression on pca components\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get lasso selected pca components and train xgboost\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    \n",
    "    #apply pca to testset and make predictions\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    \n",
    "    #get M5 predictions\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    #get naive predictions\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    locico_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    locico_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.unemployment_rate-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.unemployment_rate-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_unemployment = pd.concat([full_residuals_unemployment, residuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08d2440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (254, 236)\n",
      "number of pca components: 91\n",
      "shape after pca: (254, 91)\n",
      "0.1\n",
      "shape before pca: (254, 236)\n",
      "number of pca components: 91\n",
      "shape after pca: (254, 91)\n",
      "0.1\n",
      "shape before pca: (251, 236)\n",
      "number of pca components: 106\n",
      "shape after pca: (251, 106)\n",
      "0.1\n",
      "shape before pca: (251, 236)\n",
      "number of pca components: 106\n",
      "shape after pca: (251, 106)\n",
      "0.1\n",
      "shape before pca: (247, 236)\n",
      "number of pca components: 95\n",
      "shape after pca: (247, 95)\n",
      "0.2\n",
      "shape before pca: (247, 236)\n",
      "number of pca components: 95\n",
      "shape after pca: (247, 95)\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "target = 'income_levels'\n",
    "for city in ['berlin', 'hamburg', 'bremen']: \n",
    "    \n",
    "    country = 'DE'\n",
    "    target_city = city\n",
    "    \n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full_de[agg_full_de.assigned_city!=target_city]\n",
    "    test = agg_full_de[agg_full_de.assigned_city==target_city]\n",
    "    \n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights\n",
    "\n",
    "    #split in x and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True) \n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    #get lasso selected features and train xgboost\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #apply pca to trainset \n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    #train lasso regression on pca components\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get lasso selected pca componenets and train xgboost\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    \n",
    "    #apply pca to testset and make predictions\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    \n",
    "    #get preidction of M5\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    #get naive predictions\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    locico_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    locico_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.income_levels-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.income_levels-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_income = pd.concat([full_residuals_income, residuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af09b654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (254, 236)\n",
      "number of pca components: 91\n",
      "shape after pca: (254, 91)\n",
      "0.1\n",
      "shape before pca: (254, 236)\n",
      "number of pca components: 91\n",
      "shape after pca: (254, 91)\n",
      "0.1\n",
      "shape before pca: (251, 236)\n",
      "number of pca components: 106\n",
      "shape after pca: (251, 106)\n",
      "0.5\n",
      "shape before pca: (251, 236)\n",
      "number of pca components: 106\n",
      "shape after pca: (251, 106)\n",
      "0.5\n",
      "shape before pca: (247, 236)\n",
      "number of pca components: 95\n",
      "shape after pca: (247, 95)\n",
      "0.5\n",
      "shape before pca: (247, 236)\n",
      "number of pca components: 95\n",
      "shape after pca: (247, 95)\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "target = 'foreign_nationals'\n",
    "for city in ['berlin', 'hamburg', 'bremen']: \n",
    "    \n",
    "    country = 'DE'\n",
    "    target_city = city\n",
    "    \n",
    "    #create train dataset base on all cities but the target city\n",
    "    train = agg_full_de[agg_full_de.assigned_city!=target_city]\n",
    "    test = agg_full_de[agg_full_de.assigned_city==target_city]\n",
    "    \n",
    "    #create weights for each neighborhood inverse to the number of neighborhoods in each city\n",
    "    weights_train = []\n",
    "    for train_city in train.assigned_city.unique().tolist():\n",
    "        subset = train[train.assigned_city == train_city]\n",
    "        weights = [1 - (len(subset)/len(train))]*len(subset)\n",
    "        weights_train = weights_train + weights\n",
    "\n",
    "    #split in x and y\n",
    "    X_train = train.iloc[:,2:-5]\n",
    "    y_train = train.loc[:,[target]]\n",
    "    X_test = test.iloc[:,2:-5]\n",
    "    y_test = test.loc[:,[target]].reset_index(drop = True) \n",
    "    \n",
    "    # Boosted Lasso predicts\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf1 = GridSearchCV(lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf1.fit(X_train, y_train, sample_weight= weights_train)\n",
    "    #get lasso selected features and trainxgboost\n",
    "    cols_lasso = X_train.loc[:,clf1.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_lasso = train_xgboost(train, target, cols_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    boosted_lasso_predicts = boosted_lasso.predict(X_test[cols_lasso])\n",
    "    \n",
    "    # PCA Lasso boosted\n",
    "    #apply pca to trainset\n",
    "    comps = get_best_pca_lasso_model(agg=train,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=False)\n",
    "    pca = get_best_pca_lasso_model(agg=train ,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=False)\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(train.iloc[:,-5:].reset_index(drop = True))\n",
    "    #train lasso regression on pca components\n",
    "    alphas = [0.01, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1,2,3,5]\n",
    "    pca_lasso = linear_model.Lasso(max_iter = 50000)\n",
    "    parameters = {'alpha':alphas}\n",
    "    clf2 = GridSearchCV(pca_lasso, parameters, scoring = ['neg_mean_squared_error'], refit ='neg_mean_squared_error')\n",
    "    clf2.fit(reduced_data.iloc[:,:-5], reduced_data.loc[:,[target]], sample_weight= weights_train)\n",
    "    #get lasso selected pca components and tarin xgboost\n",
    "    cols_pca_lasso = reduced_data.iloc[:,:-5].loc[:,clf2.best_estimator_.coef_!=0].columns.tolist()\n",
    "    boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier',learner_type = 'transfer', weights = weights_train)\n",
    "    \n",
    "    #apply pca to testset and make predictions\n",
    "    reduced_test_data = pd.DataFrame(pca.transform(X_test))\n",
    "    boosted_pca_lasso_predicts = boosted_pca_lasso.predict(reduced_test_data[cols_pca_lasso])\n",
    "    \n",
    "    #get predictions for M5\n",
    "    predicts = pd.DataFrame({'boosted_lasso': boosted_lasso_predicts, 'boosted_pca_lasso': boosted_pca_lasso_predicts})\n",
    "    predicts.loc[:,'mean_model'] = predicts.mean(axis = 1)\n",
    "\n",
    "    #get naive predictions\n",
    "    naive_pred = [y_train.mean().values[0]] * len(y_test)\n",
    "    locico_results_impr.loc[city, target] = 100-(metrics.mean_squared_error(y_test, predicts.mean_model)/metrics.mean_squared_error(y_test, naive_pred)*100)\n",
    "    locico_results_r2_score.loc[city, target] = metrics.r2_score(y_test, predicts.mean_model)\n",
    "    \n",
    "    #compute residuals\n",
    "    residuals = pd.DataFrame(columns = ['residuals_naive', 'residuals_m5'])\n",
    "    residuals.loc[:,'residuals_naive'] = (y_test.foreign_nationals-naive_pred)**2\n",
    "    residuals.loc[:,'residuals_m5'] = (y_test.foreign_nationals-predicts.mean_model)**2\n",
    "    \n",
    "    full_residuals_fn = pd.concat([full_residuals_fn, residuals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "774763e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>foreign_nationals</th>\n",
       "      <th>income_levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>17.468847</td>\n",
       "      <td>-7.680231</td>\n",
       "      <td>26.136523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>7.783741</td>\n",
       "      <td>-1.566205</td>\n",
       "      <td>4.194064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>11.678524</td>\n",
       "      <td>-1.900219</td>\n",
       "      <td>18.793013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>32.501895</td>\n",
       "      <td>26.161711</td>\n",
       "      <td>26.487949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>33.993034</td>\n",
       "      <td>18.685804</td>\n",
       "      <td>15.942349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>14.290642</td>\n",
       "      <td>-18.533477</td>\n",
       "      <td>13.959362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.619447</td>\n",
       "      <td>2.527897</td>\n",
       "      <td>17.585543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unemployment_rate foreign_nationals income_levels\n",
       "marseille         17.468847         -7.680231     26.136523\n",
       "lyon               7.783741         -1.566205      4.194064\n",
       "paris             11.678524         -1.900219     18.793013\n",
       "berlin            32.501895         26.161711     26.487949\n",
       "hamburg           33.993034         18.685804     15.942349\n",
       "bremen            14.290642        -18.533477     13.959362\n",
       "mean              19.619447          2.527897     17.585543"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locico_results_impr.loc['mean'] = locico_results_impr.mean()\n",
    "locico_results_impr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13ef287f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>foreign_nationals</th>\n",
       "      <th>income_levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>0.172597</td>\n",
       "      <td>-0.102659</td>\n",
       "      <td>0.261354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>0.077668</td>\n",
       "      <td>-0.015891</td>\n",
       "      <td>0.041089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>0.114996</td>\n",
       "      <td>-0.03962</td>\n",
       "      <td>0.187774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>0.324856</td>\n",
       "      <td>0.239313</td>\n",
       "      <td>0.233561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>0.338173</td>\n",
       "      <td>0.183433</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>0.140561</td>\n",
       "      <td>-0.331548</td>\n",
       "      <td>0.116151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.194808</td>\n",
       "      <td>-0.011162</td>\n",
       "      <td>0.166304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unemployment_rate foreign_nationals income_levels\n",
       "marseille          0.172597         -0.102659      0.261354\n",
       "lyon               0.077668         -0.015891      0.041089\n",
       "paris              0.114996          -0.03962      0.187774\n",
       "berlin             0.324856          0.239313      0.233561\n",
       "hamburg            0.338173          0.183433      0.157895\n",
       "bremen             0.140561         -0.331548      0.116151\n",
       "mean               0.194808         -0.011162      0.166304"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locico_results_r2_score.loc['mean'] = locico_results_r2_score.mean()\n",
    "locico_results_r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7105a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTest: t=2.1245393944445814, p=0.033694728357986974\n"
     ]
    }
   ],
   "source": [
    "#TTest on residuals of unemployment\n",
    "t_stat, p = stats.ttest_ind(full_residuals_unemployment['residuals_naive'], full_residuals_unemployment['residuals_m5'])\n",
    "print(f'TTest: t={t_stat}, p={p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5de92a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTest: t=4.020724673492724, p=5.895844927935324e-05\n"
     ]
    }
   ],
   "source": [
    "#TTest on residuals of income\n",
    "t_stat, p = stats.ttest_ind(full_residuals_income['residuals_naive'], full_residuals_income['residuals_m5'])\n",
    "print(f'TTest: t={t_stat}, p={p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b8c1de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTest: t=-0.004499546435017125, p=0.9964101490373795\n"
     ]
    }
   ],
   "source": [
    "#TTest on residuals of foreign national rate\n",
    "t_stat, p = stats.ttest_ind(full_residuals_fn['residuals_naive'], full_residuals_fn['residuals_m5'])\n",
    "print(f'TTest: t={t_stat}, p={p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ffb30",
   "metadata": {},
   "source": [
    "### All to all city prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d20ff9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "shape before pca: (176, 236)\n",
      "number of pca components: 70\n",
      "shape after pca: (176, 70)\n",
      "0.2\n",
      "shape before pca: (176, 236)\n",
      "number of pca components: 70\n",
      "shape after pca: (176, 70)\n",
      "0.2\n",
      "shape before pca: (176, 236)\n",
      "number of pca components: 70\n",
      "shape after pca: (176, 70)\n",
      "0.2\n",
      "0.01\n",
      "shape before pca: (861, 236)\n",
      "number of pca components: 134\n",
      "shape after pca: (861, 134)\n",
      "0.01\n",
      "shape before pca: (861, 236)\n",
      "number of pca components: 134\n",
      "shape after pca: (861, 134)\n",
      "0.01\n",
      "shape before pca: (861, 236)\n",
      "number of pca components: 134\n",
      "shape after pca: (861, 134)\n",
      "0.01\n",
      "0.1\n",
      "shape before pca: (344, 236)\n",
      "number of pca components: 69\n",
      "shape after pca: (344, 69)\n",
      "0.1\n",
      "shape before pca: (344, 236)\n",
      "number of pca components: 69\n",
      "shape after pca: (344, 69)\n",
      "0.1\n",
      "shape before pca: (344, 236)\n",
      "number of pca components: 69\n",
      "shape after pca: (344, 69)\n",
      "0.1\n",
      "0.1\n",
      "shape before pca: (122, 236)\n",
      "number of pca components: 71\n",
      "shape after pca: (122, 71)\n",
      "0.1\n",
      "shape before pca: (122, 236)\n",
      "number of pca components: 71\n",
      "shape after pca: (122, 71)\n",
      "0.1\n",
      "shape before pca: (122, 236)\n",
      "number of pca components: 71\n",
      "shape after pca: (122, 71)\n",
      "0.1\n",
      "0.1\n",
      "shape before pca: (125, 236)\n",
      "number of pca components: 52\n",
      "shape after pca: (125, 52)\n",
      "0.1\n",
      "shape before pca: (125, 236)\n",
      "number of pca components: 52\n",
      "shape after pca: (125, 52)\n",
      "0.1\n",
      "shape before pca: (125, 236)\n",
      "number of pca components: 52\n",
      "shape after pca: (125, 52)\n",
      "0.1\n",
      "0.2\n",
      "shape before pca: (129, 236)\n",
      "number of pca components: 63\n",
      "shape after pca: (129, 63)\n",
      "0.1\n",
      "shape before pca: (129, 236)\n",
      "number of pca components: 63\n",
      "shape after pca: (129, 63)\n",
      "0.1\n",
      "shape before pca: (129, 236)\n",
      "number of pca components: 63\n",
      "shape after pca: (129, 63)\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# create outout dataframe\n",
    "improvement_matrix = pd.DataFrame(columns = ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen'])\n",
    "r2_score_matrix = pd.DataFrame(columns = ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen'])\n",
    "#set target\n",
    "target = 'unemployment_rate'\n",
    "for train_city in ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen']:\n",
    "    \n",
    "    predicts_master = pd.DataFrame(columns = ['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted', 'y_pred_mean_model', 'y_pred_naive'])\n",
    "    #load data depending on country\n",
    "    if (train_city in ['marseille', 'lyon', 'paris']):\n",
    "        country = 'FR'\n",
    "    else:\n",
    "        country = 'DE'\n",
    "    agg_subset = agg_full[agg_full.assigned_city==train_city].reset_index(drop = True)\n",
    "\n",
    "    \n",
    "    # train lasso boosted (M2)\n",
    "    cols_lasso = get_best_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015, density_type='count', radius = 1000, output ='used_columns')\n",
    "    predicts = train_xgboost(agg_subset, target, cols_lasso, 'predicts')\n",
    "    lasso_xgb = train_xgboost(agg_subset, target, cols_lasso, 'classifier')\n",
    "    \n",
    "    predicts_master.loc[:, 'y_pred_lasso_boosted'] = predicts.y_pred\n",
    "    predicts_master.loc[:, 'y_pred_naive'] = predicts.naive\n",
    "\n",
    "    # PCA Lasso boosted (M4)\n",
    "    comps = get_best_pca_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'components')\n",
    "    pca = get_best_pca_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier')\n",
    "    cols_pca_lasso = get_best_pca_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'used_columns')\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(agg_subset.iloc[:,-5:])\n",
    "    predicts = train_xgboost(reduced_data, target, cols_pca_lasso, 'predicts')\n",
    "    pca_lasso_xgb = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier')\n",
    "    predicts_master.loc[:,'y_pred_pca_lasso_boosted'] = predicts.y_pred\n",
    "\n",
    "    #get predictions of M5\n",
    "    predicts_master.loc[:, 'y_pred_mean_model'] = predicts_master[['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted']].mean(axis = 1)\n",
    "    predicts_master.loc[:, 'y_test'] = predicts.y_test\n",
    "    \n",
    "    #compute performance metrics\n",
    "    naive_mse = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_naive) \n",
    "    mse_mean_model = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_mean_model)\n",
    "    improvement_mean_model = 100 - (mse_mean_model/naive_mse)*100\n",
    "    \n",
    "    improvement_matrix.loc[train_city, train_city] = improvement_mean_model\n",
    "    r2_score_matrix.loc[train_city, train_city] = metrics.r2_score(predicts_master.y_test, predicts_master.y_pred_mean_model)\n",
    "\n",
    "    # used the trained model and apply it as it is to the other cities\n",
    "    for target_city in ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen']:\n",
    "        #make sure target city is different from train city\n",
    "        if(target_city != train_city):\n",
    "            \n",
    "            #determine country of city \n",
    "            if (target_city in ['marseille', 'lyon', 'paris']):\n",
    "                country = 'FR'\n",
    "            else:\n",
    "                country = 'DE'\n",
    "            \n",
    "            predicts_master = pd.DataFrame(columns = ['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted', 'y_pred_mean_model', 'y_pred_naive'])\n",
    "            #filter testdata\n",
    "            test_data = agg_full[agg_full.assigned_city==target_city].reset_index(drop = True)\n",
    "\n",
    "            #get predictions of M2\n",
    "            predicts_master.loc[:,'y_pred_lasso_boosted'] = lasso_xgb.predict(test_data.iloc[:,2:-5][cols_lasso])\n",
    "\n",
    "            #get predictions of M4\n",
    "            reduced_data = pd.DataFrame(pca.transform(test_data.iloc[:,2:-5]))\n",
    "            reduced_data = reduced_data.join(test_data.iloc[:,-5:])\n",
    "            predicts_master.loc[:,'y_pred_pca_lasso_boosted'] = pca_lasso_xgb.predict(reduced_data.iloc[:,:-5][cols_pca_lasso])\n",
    "\n",
    "            #combine M2 and M4 predictions to M5\n",
    "            predicts_master.loc[:, 'y_pred_mean_model'] = predicts_master[['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted']].mean(axis = 1)\n",
    "            predicts_master.loc[:, 'y_test'] = test_data[target]\n",
    "            predicts_master.loc[:, 'y_pred_naive'] = test_data[target].mean()\n",
    "\n",
    "            #compute performance metrics\n",
    "            naive_mse = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_naive) \n",
    "            mse_mean_model = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_mean_model)\n",
    "            improvement_mean_model = 100 - (mse_mean_model/naive_mse)*100\n",
    "\n",
    "            improvement_matrix.loc[train_city, target_city] = improvement_mean_model\n",
    "            r2_score_matrix.loc[train_city, target_city] = metrics.r2_score(predicts_master.y_test, predicts_master.y_pred_mean_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a36b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyon</th>\n",
       "      <th>paris</th>\n",
       "      <th>marseille</th>\n",
       "      <th>berlin</th>\n",
       "      <th>hamburg</th>\n",
       "      <th>bremen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>42.387262</td>\n",
       "      <td>-5.008299</td>\n",
       "      <td>2.008875</td>\n",
       "      <td>-19.230927</td>\n",
       "      <td>-27.25256</td>\n",
       "      <td>-17.609691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>5.084881</td>\n",
       "      <td>36.334713</td>\n",
       "      <td>8.570473</td>\n",
       "      <td>-110.828487</td>\n",
       "      <td>-104.829046</td>\n",
       "      <td>-97.911119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>-13.058004</td>\n",
       "      <td>14.278103</td>\n",
       "      <td>46.929571</td>\n",
       "      <td>25.176568</td>\n",
       "      <td>0.01777</td>\n",
       "      <td>5.574265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>-19.014588</td>\n",
       "      <td>-8.327019</td>\n",
       "      <td>12.433117</td>\n",
       "      <td>38.398618</td>\n",
       "      <td>27.555578</td>\n",
       "      <td>-7.580129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>-21.631801</td>\n",
       "      <td>-20.104518</td>\n",
       "      <td>-10.837818</td>\n",
       "      <td>38.137327</td>\n",
       "      <td>50.256995</td>\n",
       "      <td>31.791296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>-17.974252</td>\n",
       "      <td>-28.299383</td>\n",
       "      <td>-21.523371</td>\n",
       "      <td>9.791983</td>\n",
       "      <td>25.823198</td>\n",
       "      <td>56.940528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                lyon      paris  marseille      berlin     hamburg     bremen\n",
       "lyon       42.387262  -5.008299   2.008875  -19.230927   -27.25256 -17.609691\n",
       "paris       5.084881  36.334713   8.570473 -110.828487 -104.829046 -97.911119\n",
       "marseille -13.058004  14.278103  46.929571   25.176568     0.01777   5.574265\n",
       "berlin    -19.014588  -8.327019  12.433117   38.398618   27.555578  -7.580129\n",
       "hamburg   -21.631801 -20.104518 -10.837818   38.137327   50.256995  31.791296\n",
       "bremen    -17.974252 -28.299383 -21.523371    9.791983   25.823198  56.940528"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improvement_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2756b3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyon</th>\n",
       "      <th>paris</th>\n",
       "      <th>marseille</th>\n",
       "      <th>berlin</th>\n",
       "      <th>hamburg</th>\n",
       "      <th>bremen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>0.422793</td>\n",
       "      <td>-0.050083</td>\n",
       "      <td>0.020089</td>\n",
       "      <td>-0.192309</td>\n",
       "      <td>-0.272526</td>\n",
       "      <td>-0.176097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>0.050849</td>\n",
       "      <td>0.35436</td>\n",
       "      <td>0.085705</td>\n",
       "      <td>-1.108285</td>\n",
       "      <td>-1.04829</td>\n",
       "      <td>-0.979111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>-0.13058</td>\n",
       "      <td>0.142781</td>\n",
       "      <td>0.468572</td>\n",
       "      <td>0.251766</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.055743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>-0.190146</td>\n",
       "      <td>-0.08327</td>\n",
       "      <td>0.124331</td>\n",
       "      <td>0.383826</td>\n",
       "      <td>0.275556</td>\n",
       "      <td>-0.075801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>-0.216318</td>\n",
       "      <td>-0.201045</td>\n",
       "      <td>-0.108378</td>\n",
       "      <td>0.381373</td>\n",
       "      <td>0.440679</td>\n",
       "      <td>0.317913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>-0.179743</td>\n",
       "      <td>-0.282994</td>\n",
       "      <td>-0.215234</td>\n",
       "      <td>0.09792</td>\n",
       "      <td>0.258232</td>\n",
       "      <td>0.550801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lyon     paris marseille    berlin   hamburg    bremen\n",
       "lyon       0.422793 -0.050083  0.020089 -0.192309 -0.272526 -0.176097\n",
       "paris      0.050849   0.35436  0.085705 -1.108285  -1.04829 -0.979111\n",
       "marseille  -0.13058  0.142781  0.468572  0.251766  0.000178  0.055743\n",
       "berlin    -0.190146  -0.08327  0.124331  0.383826  0.275556 -0.075801\n",
       "hamburg   -0.216318 -0.201045 -0.108378  0.381373  0.440679  0.317913\n",
       "bremen    -0.179743 -0.282994 -0.215234   0.09792  0.258232  0.550801"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9444bcd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "shape before pca: (176, 236)\n",
      "number of pca components: 70\n",
      "shape after pca: (176, 70)\n",
      "0.2\n",
      "shape before pca: (176, 236)\n",
      "number of pca components: 70\n",
      "shape after pca: (176, 70)\n",
      "0.2\n",
      "shape before pca: (176, 236)\n",
      "number of pca components: 70\n",
      "shape after pca: (176, 70)\n",
      "0.2\n",
      "0.01\n",
      "shape before pca: (861, 236)\n",
      "number of pca components: 134\n",
      "shape after pca: (861, 134)\n",
      "0.01\n",
      "shape before pca: (861, 236)\n",
      "number of pca components: 134\n",
      "shape after pca: (861, 134)\n",
      "0.01\n",
      "shape before pca: (861, 236)\n",
      "number of pca components: 134\n",
      "shape after pca: (861, 134)\n",
      "0.01\n",
      "0.01\n",
      "shape before pca: (344, 236)\n",
      "number of pca components: 69\n",
      "shape after pca: (344, 69)\n",
      "0.01\n",
      "shape before pca: (344, 236)\n",
      "number of pca components: 69\n",
      "shape after pca: (344, 69)\n",
      "0.01\n",
      "shape before pca: (344, 236)\n",
      "number of pca components: 69\n",
      "shape after pca: (344, 69)\n",
      "0.01\n",
      "0.1\n",
      "shape before pca: (122, 236)\n",
      "number of pca components: 71\n",
      "shape after pca: (122, 71)\n",
      "0.1\n",
      "shape before pca: (122, 236)\n",
      "number of pca components: 71\n",
      "shape after pca: (122, 71)\n",
      "0.1\n",
      "shape before pca: (122, 236)\n",
      "number of pca components: 71\n",
      "shape after pca: (122, 71)\n",
      "0.1\n",
      "0.1\n",
      "shape before pca: (125, 236)\n",
      "number of pca components: 52\n",
      "shape after pca: (125, 52)\n",
      "0.5\n",
      "shape before pca: (125, 236)\n",
      "number of pca components: 52\n",
      "shape after pca: (125, 52)\n",
      "0.5\n",
      "shape before pca: (125, 236)\n",
      "number of pca components: 52\n",
      "shape after pca: (125, 52)\n",
      "0.5\n",
      "0.1\n",
      "shape before pca: (129, 236)\n",
      "number of pca components: 63\n",
      "shape after pca: (129, 63)\n",
      "0.5\n",
      "shape before pca: (129, 236)\n",
      "number of pca components: 63\n",
      "shape after pca: (129, 63)\n",
      "0.5\n",
      "shape before pca: (129, 236)\n",
      "number of pca components: 63\n",
      "shape after pca: (129, 63)\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# create outout dataframe\n",
    "improvement_matrix = pd.DataFrame(columns = ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen'])\n",
    "r2_score_matrix = pd.DataFrame(columns = ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen'])\n",
    "#set target\n",
    "target = 'foreign_nationals'\n",
    "for train_city in ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen']:\n",
    "    \n",
    "    predicts_master = pd.DataFrame(columns = ['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted', 'y_pred_mean_model', 'y_pred_naive'])\n",
    "    #load data depending on country\n",
    "    if (train_city in ['marseille', 'lyon', 'paris']):\n",
    "        country = 'FR'\n",
    "    else:\n",
    "        country = 'DE'\n",
    "    agg_subset = agg_full[agg_full.assigned_city==train_city].reset_index(drop = True)\n",
    "\n",
    "    \n",
    "    # train lasso boosted (M2)\n",
    "    cols_lasso = get_best_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015, density_type='count', radius = 1000, output ='used_columns')\n",
    "    predicts = train_xgboost(agg_subset, target, cols_lasso, 'predicts')\n",
    "    lasso_xgb = train_xgboost(agg_subset, target, cols_lasso, 'classifier')\n",
    "    \n",
    "    predicts_master.loc[:, 'y_pred_lasso_boosted'] = predicts.y_pred\n",
    "    predicts_master.loc[:, 'y_pred_naive'] = predicts.naive\n",
    "\n",
    "    # PCA Lasso boosted (M4)\n",
    "    comps = get_best_pca_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'components')\n",
    "    pca = get_best_pca_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier')\n",
    "    cols_pca_lasso = get_best_pca_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'used_columns')\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(agg_subset.iloc[:,-5:])\n",
    "    predicts = train_xgboost(reduced_data, target, cols_pca_lasso, 'predicts')\n",
    "    pca_lasso_xgb = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier')\n",
    "    predicts_master.loc[:,'y_pred_pca_lasso_boosted'] = predicts.y_pred\n",
    "\n",
    "    #get predictions of M5\n",
    "    predicts_master.loc[:, 'y_pred_mean_model'] = predicts_master[['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted']].mean(axis = 1)\n",
    "    predicts_master.loc[:, 'y_test'] = predicts.y_test\n",
    "    \n",
    "    #compute performance metrics\n",
    "    naive_mse = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_naive) \n",
    "    mse_mean_model = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_mean_model)\n",
    "    improvement_mean_model = 100 - (mse_mean_model/naive_mse)*100\n",
    "    \n",
    "    improvement_matrix.loc[train_city, train_city] = improvement_mean_model\n",
    "    r2_score_matrix.loc[train_city, train_city] = metrics.r2_score(predicts_master.y_test, predicts_master.y_pred_mean_model)\n",
    "\n",
    "    # used the trained model and apply it as it is to the other cities\n",
    "    for target_city in ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen']:\n",
    "        #make sure target city is different from train city\n",
    "        if(target_city != train_city):\n",
    "            \n",
    "            #determine country of city \n",
    "            if (target_city in ['marseille', 'lyon', 'paris']):\n",
    "                country = 'FR'\n",
    "            else:\n",
    "                country = 'DE'\n",
    "            \n",
    "            predicts_master = pd.DataFrame(columns = ['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted', 'y_pred_mean_model', 'y_pred_naive'])\n",
    "            #filter testdata\n",
    "            test_data = agg_full[agg_full.assigned_city==target_city].reset_index(drop = True)\n",
    "\n",
    "            #get predictions of M2\n",
    "            predicts_master.loc[:,'y_pred_lasso_boosted'] = lasso_xgb.predict(test_data.iloc[:,2:-5][cols_lasso])\n",
    "\n",
    "            #get predictions of M4\n",
    "            reduced_data = pd.DataFrame(pca.transform(test_data.iloc[:,2:-5]))\n",
    "            reduced_data = reduced_data.join(test_data.iloc[:,-5:])\n",
    "            predicts_master.loc[:,'y_pred_pca_lasso_boosted'] = pca_lasso_xgb.predict(reduced_data.iloc[:,:-5][cols_pca_lasso])\n",
    "\n",
    "            #combine M2 and M4 predictions to M5\n",
    "            predicts_master.loc[:, 'y_pred_mean_model'] = predicts_master[['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted']].mean(axis = 1)\n",
    "            predicts_master.loc[:, 'y_test'] = test_data[target]\n",
    "            predicts_master.loc[:, 'y_pred_naive'] = test_data[target].mean()\n",
    "\n",
    "            #compute performance metrics\n",
    "            naive_mse = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_naive) \n",
    "            mse_mean_model = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_mean_model)\n",
    "            improvement_mean_model = 100 - (mse_mean_model/naive_mse)*100\n",
    "\n",
    "            improvement_matrix.loc[train_city, target_city] = improvement_mean_model\n",
    "            r2_score_matrix.loc[train_city, target_city] = metrics.r2_score(predicts_master.y_test, predicts_master.y_pred_mean_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dae8a183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyon</th>\n",
       "      <th>paris</th>\n",
       "      <th>marseille</th>\n",
       "      <th>berlin</th>\n",
       "      <th>hamburg</th>\n",
       "      <th>bremen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>27.669349</td>\n",
       "      <td>3.678184</td>\n",
       "      <td>4.345853</td>\n",
       "      <td>-10.638002</td>\n",
       "      <td>-1.56839</td>\n",
       "      <td>-30.527752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>5.722788</td>\n",
       "      <td>35.326112</td>\n",
       "      <td>-4.636117</td>\n",
       "      <td>-15.310389</td>\n",
       "      <td>-14.889929</td>\n",
       "      <td>-52.978752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>-18.435029</td>\n",
       "      <td>-14.281441</td>\n",
       "      <td>72.405118</td>\n",
       "      <td>40.503535</td>\n",
       "      <td>10.713761</td>\n",
       "      <td>-18.719399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>-35.181444</td>\n",
       "      <td>0.877989</td>\n",
       "      <td>20.654546</td>\n",
       "      <td>67.603515</td>\n",
       "      <td>-0.428588</td>\n",
       "      <td>-21.65871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>-20.895484</td>\n",
       "      <td>-40.023319</td>\n",
       "      <td>4.035169</td>\n",
       "      <td>1.4879</td>\n",
       "      <td>25.432159</td>\n",
       "      <td>-39.840821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>-28.167978</td>\n",
       "      <td>-12.88348</td>\n",
       "      <td>11.717505</td>\n",
       "      <td>22.545811</td>\n",
       "      <td>6.403182</td>\n",
       "      <td>32.320905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                lyon      paris  marseille     berlin    hamburg     bremen\n",
       "lyon       27.669349   3.678184   4.345853 -10.638002   -1.56839 -30.527752\n",
       "paris       5.722788  35.326112  -4.636117 -15.310389 -14.889929 -52.978752\n",
       "marseille -18.435029 -14.281441  72.405118  40.503535  10.713761 -18.719399\n",
       "berlin    -35.181444   0.877989  20.654546  67.603515  -0.428588  -21.65871\n",
       "hamburg   -20.895484 -40.023319   4.035169     1.4879  25.432159 -39.840821\n",
       "bremen    -28.167978  -12.88348  11.717505  22.545811   6.403182  32.320905"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improvement_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84423f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyon</th>\n",
       "      <th>paris</th>\n",
       "      <th>marseille</th>\n",
       "      <th>berlin</th>\n",
       "      <th>hamburg</th>\n",
       "      <th>bremen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>0.275161</td>\n",
       "      <td>0.036782</td>\n",
       "      <td>0.043459</td>\n",
       "      <td>-0.10638</td>\n",
       "      <td>-0.015684</td>\n",
       "      <td>-0.305278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>0.057228</td>\n",
       "      <td>0.339217</td>\n",
       "      <td>-0.046361</td>\n",
       "      <td>-0.153104</td>\n",
       "      <td>-0.148899</td>\n",
       "      <td>-0.529788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>-0.18435</td>\n",
       "      <td>-0.142814</td>\n",
       "      <td>0.716842</td>\n",
       "      <td>0.405035</td>\n",
       "      <td>0.107138</td>\n",
       "      <td>-0.187194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>-0.351814</td>\n",
       "      <td>0.00878</td>\n",
       "      <td>0.206545</td>\n",
       "      <td>0.66505</td>\n",
       "      <td>-0.004286</td>\n",
       "      <td>-0.216587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>-0.208955</td>\n",
       "      <td>-0.400233</td>\n",
       "      <td>0.040352</td>\n",
       "      <td>0.014879</td>\n",
       "      <td>0.059483</td>\n",
       "      <td>-0.398408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>-0.28168</td>\n",
       "      <td>-0.128835</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>0.225458</td>\n",
       "      <td>0.064032</td>\n",
       "      <td>0.314615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lyon     paris marseille    berlin   hamburg    bremen\n",
       "lyon       0.275161  0.036782  0.043459  -0.10638 -0.015684 -0.305278\n",
       "paris      0.057228  0.339217 -0.046361 -0.153104 -0.148899 -0.529788\n",
       "marseille  -0.18435 -0.142814  0.716842  0.405035  0.107138 -0.187194\n",
       "berlin    -0.351814   0.00878  0.206545   0.66505 -0.004286 -0.216587\n",
       "hamburg   -0.208955 -0.400233  0.040352  0.014879  0.059483 -0.398408\n",
       "bremen     -0.28168 -0.128835  0.117175  0.225458  0.064032  0.314615"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "854dbc74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "shape before pca: (176, 236)\n",
      "number of pca components: 70\n",
      "shape after pca: (176, 70)\n",
      "0.1\n",
      "shape before pca: (176, 236)\n",
      "number of pca components: 70\n",
      "shape after pca: (176, 70)\n",
      "0.1\n",
      "shape before pca: (176, 236)\n",
      "number of pca components: 70\n",
      "shape after pca: (176, 70)\n",
      "0.1\n",
      "0.01\n",
      "shape before pca: (861, 236)\n",
      "number of pca components: 134\n",
      "shape after pca: (861, 134)\n",
      "0.01\n",
      "shape before pca: (861, 236)\n",
      "number of pca components: 134\n",
      "shape after pca: (861, 134)\n",
      "0.01\n",
      "shape before pca: (861, 236)\n",
      "number of pca components: 134\n",
      "shape after pca: (861, 134)\n",
      "0.01\n",
      "0.01\n",
      "shape before pca: (344, 236)\n",
      "number of pca components: 69\n",
      "shape after pca: (344, 69)\n",
      "0.01\n",
      "shape before pca: (344, 236)\n",
      "number of pca components: 69\n",
      "shape after pca: (344, 69)\n",
      "0.01\n",
      "shape before pca: (344, 236)\n",
      "number of pca components: 69\n",
      "shape after pca: (344, 69)\n",
      "0.01\n",
      "0.1\n",
      "shape before pca: (122, 236)\n",
      "number of pca components: 71\n",
      "shape after pca: (122, 71)\n",
      "0.1\n",
      "shape before pca: (122, 236)\n",
      "number of pca components: 71\n",
      "shape after pca: (122, 71)\n",
      "0.1\n",
      "shape before pca: (122, 236)\n",
      "number of pca components: 71\n",
      "shape after pca: (122, 71)\n",
      "0.1\n",
      "0.1\n",
      "shape before pca: (125, 236)\n",
      "number of pca components: 52\n",
      "shape after pca: (125, 52)\n",
      "0.1\n",
      "shape before pca: (125, 236)\n",
      "number of pca components: 52\n",
      "shape after pca: (125, 52)\n",
      "0.1\n",
      "shape before pca: (125, 236)\n",
      "number of pca components: 52\n",
      "shape after pca: (125, 52)\n",
      "0.1\n",
      "0.1\n",
      "shape before pca: (129, 236)\n",
      "number of pca components: 63\n",
      "shape after pca: (129, 63)\n",
      "0.2\n",
      "shape before pca: (129, 236)\n",
      "number of pca components: 63\n",
      "shape after pca: (129, 63)\n",
      "0.2\n",
      "shape before pca: (129, 236)\n",
      "number of pca components: 63\n",
      "shape after pca: (129, 63)\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# create outout dataframe\n",
    "improvement_matrix = pd.DataFrame(columns = ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen'])\n",
    "r2_score_matrix = pd.DataFrame(columns = ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen'])\n",
    "#set target\n",
    "target = 'income_levels'\n",
    "for train_city in ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen']:\n",
    "    \n",
    "    predicts_master = pd.DataFrame(columns = ['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted', 'y_pred_mean_model', 'y_pred_naive'])\n",
    "    #load data depending on country\n",
    "    if (train_city in ['marseille', 'lyon', 'paris']):\n",
    "        country = 'FR'\n",
    "    else:\n",
    "        country = 'DE'\n",
    "    agg_subset = agg_full[agg_full.assigned_city==train_city].reset_index(drop = True)\n",
    "\n",
    "    \n",
    "    # train lasso boosted (M2)\n",
    "    cols_lasso = get_best_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015, density_type='count', radius = 1000, output ='used_columns')\n",
    "    predicts = train_xgboost(agg_subset, target, cols_lasso, 'predicts')\n",
    "    lasso_xgb = train_xgboost(agg_subset, target, cols_lasso, 'classifier')\n",
    "    \n",
    "    predicts_master.loc[:, 'y_pred_lasso_boosted'] = predicts.y_pred\n",
    "    predicts_master.loc[:, 'y_pred_naive'] = predicts.naive\n",
    "\n",
    "    # PCA Lasso boosted (M4)\n",
    "    comps = get_best_pca_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'components')\n",
    "    pca = get_best_pca_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier')\n",
    "    cols_pca_lasso = get_best_pca_lasso_model(agg=agg_subset, target=target, city=train_city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'used_columns')\n",
    "    reduced_data = pd.DataFrame(comps)\n",
    "    reduced_data = reduced_data.join(agg_subset.iloc[:,-5:])\n",
    "    predicts = train_xgboost(reduced_data, target, cols_pca_lasso, 'predicts')\n",
    "    pca_lasso_xgb = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier')\n",
    "    predicts_master.loc[:,'y_pred_pca_lasso_boosted'] = predicts.y_pred\n",
    "\n",
    "    #get predictions of M5\n",
    "    predicts_master.loc[:, 'y_pred_mean_model'] = predicts_master[['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted']].mean(axis = 1)\n",
    "    predicts_master.loc[:, 'y_test'] = predicts.y_test\n",
    "    \n",
    "    #compute performance metrics\n",
    "    naive_mse = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_naive) \n",
    "    mse_mean_model = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_mean_model)\n",
    "    improvement_mean_model = 100 - (mse_mean_model/naive_mse)*100\n",
    "    \n",
    "    improvement_matrix.loc[train_city, train_city] = improvement_mean_model\n",
    "    r2_score_matrix.loc[train_city, train_city] = metrics.r2_score(predicts_master.y_test, predicts_master.y_pred_mean_model)\n",
    "\n",
    "    # used the trained model and apply it as it is to the other cities\n",
    "    for target_city in ['lyon', 'paris', 'marseille', 'berlin', 'hamburg', 'bremen']:\n",
    "        #make sure target city is different from train city\n",
    "        if(target_city != train_city):\n",
    "            \n",
    "            #determine country of city \n",
    "            if (target_city in ['marseille', 'lyon', 'paris']):\n",
    "                country = 'FR'\n",
    "            else:\n",
    "                country = 'DE'\n",
    "            \n",
    "            predicts_master = pd.DataFrame(columns = ['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted', 'y_pred_mean_model', 'y_pred_naive'])\n",
    "            #filter testdata\n",
    "            test_data = agg_full[agg_full.assigned_city==target_city].reset_index(drop = True)\n",
    "\n",
    "            #get predictions of M2\n",
    "            predicts_master.loc[:,'y_pred_lasso_boosted'] = lasso_xgb.predict(test_data.iloc[:,2:-5][cols_lasso])\n",
    "\n",
    "            #get predictions of M4\n",
    "            reduced_data = pd.DataFrame(pca.transform(test_data.iloc[:,2:-5]))\n",
    "            reduced_data = reduced_data.join(test_data.iloc[:,-5:])\n",
    "            predicts_master.loc[:,'y_pred_pca_lasso_boosted'] = pca_lasso_xgb.predict(reduced_data.iloc[:,:-5][cols_pca_lasso])\n",
    "\n",
    "            #combine M2 and M4 predictions to M5\n",
    "            predicts_master.loc[:, 'y_pred_mean_model'] = predicts_master[['y_pred_lasso_boosted', 'y_pred_pca_lasso_boosted']].mean(axis = 1)\n",
    "            predicts_master.loc[:, 'y_test'] = test_data[target]\n",
    "            predicts_master.loc[:, 'y_pred_naive'] = test_data[target].mean()\n",
    "\n",
    "            #compute performance metrics\n",
    "            naive_mse = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_naive) \n",
    "            mse_mean_model = metrics.mean_squared_error(predicts_master.y_test, predicts_master.y_pred_mean_model)\n",
    "            improvement_mean_model = 100 - (mse_mean_model/naive_mse)*100\n",
    "\n",
    "            improvement_matrix.loc[train_city, target_city] = improvement_mean_model\n",
    "            r2_score_matrix.loc[train_city, target_city] = metrics.r2_score(predicts_master.y_test, predicts_master.y_pred_mean_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ef825f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyon</th>\n",
       "      <th>paris</th>\n",
       "      <th>marseille</th>\n",
       "      <th>berlin</th>\n",
       "      <th>hamburg</th>\n",
       "      <th>bremen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>57.652806</td>\n",
       "      <td>-18.648556</td>\n",
       "      <td>-6.881163</td>\n",
       "      <td>-33.784398</td>\n",
       "      <td>-16.021425</td>\n",
       "      <td>-19.262632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>-1.703752</td>\n",
       "      <td>74.625626</td>\n",
       "      <td>18.331365</td>\n",
       "      <td>7.726413</td>\n",
       "      <td>-2.025867</td>\n",
       "      <td>-9.452516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>-3.09627</td>\n",
       "      <td>24.203725</td>\n",
       "      <td>75.309903</td>\n",
       "      <td>0.537203</td>\n",
       "      <td>-0.14184</td>\n",
       "      <td>-2.34901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>-12.370467</td>\n",
       "      <td>4.711074</td>\n",
       "      <td>2.237851</td>\n",
       "      <td>29.731272</td>\n",
       "      <td>12.085897</td>\n",
       "      <td>-2.648139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>-22.138298</td>\n",
       "      <td>4.940516</td>\n",
       "      <td>6.012667</td>\n",
       "      <td>22.020487</td>\n",
       "      <td>47.218826</td>\n",
       "      <td>11.799119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>-31.671434</td>\n",
       "      <td>-4.316979</td>\n",
       "      <td>-17.581762</td>\n",
       "      <td>8.666853</td>\n",
       "      <td>-14.314297</td>\n",
       "      <td>45.940758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                lyon      paris  marseille     berlin    hamburg     bremen\n",
       "lyon       57.652806 -18.648556  -6.881163 -33.784398 -16.021425 -19.262632\n",
       "paris      -1.703752  74.625626  18.331365   7.726413  -2.025867  -9.452516\n",
       "marseille   -3.09627  24.203725  75.309903   0.537203   -0.14184   -2.34901\n",
       "berlin    -12.370467   4.711074   2.237851  29.731272  12.085897  -2.648139\n",
       "hamburg   -22.138298   4.940516   6.012667  22.020487  47.218826  11.799119\n",
       "bremen    -31.671434  -4.316979 -17.581762   8.666853 -14.314297  45.940758"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improvement_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2064b964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyon</th>\n",
       "      <th>paris</th>\n",
       "      <th>marseille</th>\n",
       "      <th>berlin</th>\n",
       "      <th>hamburg</th>\n",
       "      <th>bremen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>0.576165</td>\n",
       "      <td>-0.186486</td>\n",
       "      <td>-0.068812</td>\n",
       "      <td>-0.337844</td>\n",
       "      <td>-0.160214</td>\n",
       "      <td>-0.192626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>-0.017038</td>\n",
       "      <td>0.744844</td>\n",
       "      <td>0.183314</td>\n",
       "      <td>0.077264</td>\n",
       "      <td>-0.020259</td>\n",
       "      <td>-0.094525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>-0.030963</td>\n",
       "      <td>0.242037</td>\n",
       "      <td>0.752903</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>-0.02349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>-0.123705</td>\n",
       "      <td>0.047111</td>\n",
       "      <td>0.022379</td>\n",
       "      <td>0.296566</td>\n",
       "      <td>0.120859</td>\n",
       "      <td>-0.026481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>-0.221383</td>\n",
       "      <td>0.049405</td>\n",
       "      <td>0.060127</td>\n",
       "      <td>0.220205</td>\n",
       "      <td>0.449712</td>\n",
       "      <td>0.117991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>-0.316714</td>\n",
       "      <td>-0.04317</td>\n",
       "      <td>-0.175818</td>\n",
       "      <td>0.086669</td>\n",
       "      <td>-0.143143</td>\n",
       "      <td>0.348394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lyon     paris marseille    berlin   hamburg    bremen\n",
       "lyon       0.576165 -0.186486 -0.068812 -0.337844 -0.160214 -0.192626\n",
       "paris     -0.017038  0.744844  0.183314  0.077264 -0.020259 -0.094525\n",
       "marseille -0.030963  0.242037  0.752903  0.005372 -0.001418  -0.02349\n",
       "berlin    -0.123705  0.047111  0.022379  0.296566  0.120859 -0.026481\n",
       "hamburg   -0.221383  0.049405  0.060127  0.220205  0.449712  0.117991\n",
       "bremen    -0.316714  -0.04317 -0.175818  0.086669 -0.143143  0.348394"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d1ee5",
   "metadata": {},
   "source": [
    "## Meta Learner trained on all cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5e27a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner_results = pd.DataFrame(columns = ['unemployment_rate', 'foreign_nationals', 'income_levels'])\n",
    "meta_learner_r2_score = pd.DataFrame(columns = ['unemployment_rate', 'foreign_nationals', 'income_levels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74de0828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data: (1263, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (344, 243)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 133)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 58)\n",
      "shape of training data: (1431, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (176, 243)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 67)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 133)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 58)\n",
      "shape of training data: (746, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (861, 243)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 67)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 66)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 58)\n",
      "shape of training data: (1485, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (122, 243)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 67)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 133)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 43)\n",
      "shape of training data: (1482, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (125, 243)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 67)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 133)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 53)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 58)\n",
      "shape of training data: (1478, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (129, 243)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 67)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 133)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 58)\n"
     ]
    }
   ],
   "source": [
    "#set target\n",
    "target = 'unemployment_rate'\n",
    "\n",
    "for target_city in ['marseille', 'lyon', 'paris', 'berlin', 'hamburg', 'bremen']:\n",
    "\n",
    "    train_full = pd.DataFrame(columns = agg_full.columns)\n",
    "    meta_train_full = pd.DataFrame(columns = agg_full.columns)\n",
    "    test_full = pd.DataFrame(columns = agg_full.columns)\n",
    "\n",
    "    # filter data for respective city\n",
    "    for city in ['marseille', 'lyon', 'paris', 'berlin', 'hamburg', 'bremen']:\n",
    "\n",
    "        #get city subset which is used for training\n",
    "        subset = agg_full[agg_full.assigned_city == city]\n",
    "\n",
    "        if (target_city != city):\n",
    "        # create three subsets - training data, meta_training_data, test_data. If city is \"traget city\" is will be used as testset\n",
    "            train, meta_train = train_test_split(subset, test_size=30, random_state=41)\n",
    "            # append created datasets\n",
    "            train_full = train_full.append(train)\n",
    "            meta_train_full = meta_train_full.append(meta_train)\n",
    "\n",
    "        else:\n",
    "            test_full = subset\n",
    "\n",
    "    #reset index for all three subsets\n",
    "    train_full = train_full.reset_index(drop = True)\n",
    "    meta_train_full = meta_train_full.reset_index(drop = True)\n",
    "    test_full = test_full.reset_index(drop = True)\n",
    "\n",
    "    print('shape of training data: '+str(train_full.shape))\n",
    "    print('shape of meta training data: '+str(meta_train_full.shape))\n",
    "    print('shape of test data: '+str(test_full.shape))\n",
    "\n",
    "    cities = ['marseille', 'lyon', 'paris', 'hamburg', 'bremen', 'berlin', target]\n",
    "    cities.remove(target_city)\n",
    "\n",
    "    #create dataframe to fill for meta learner training\n",
    "    meta_learner_train = pd.DataFrame(columns = cities)\n",
    "    meta_learner_test = pd.DataFrame(columns = cities)\n",
    "\n",
    "    # split data in feature and target\n",
    "    X_meta_train_full = meta_train_full.iloc[:,2:-5]\n",
    "    y_meta_train_full = meta_train_full[[target]]\n",
    "\n",
    "    X_test_full = test_full.iloc[:,2:-5]\n",
    "    y_test_full = test_full[[target]]\n",
    "\n",
    "    for city in ['marseille', 'lyon', 'paris']:\n",
    "        country = 'FR'\n",
    "\n",
    "        if(city != target_city):\n",
    "            #filter out data of respective city\n",
    "            city_training_data = train_full[train_full.assigned_city == city]\n",
    "\n",
    "            # Lasso Boosted\n",
    "            #get columns lasso model selects\n",
    "            cols_lasso = get_best_lasso_model(agg=city_training_data, target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output ='used_columns',meta_learner= True)\n",
    "            # get xgboost classifier\n",
    "            boosted_lasso = train_xgboost(city_training_data, target, cols_lasso, 'classifier', learner_type = 'meta')\n",
    "            #make prediction for meta_train data and test data\n",
    "            boosted_lasso_predicts_meta = boosted_lasso.predict(X_meta_train_full[cols_lasso])\n",
    "            boosted_lasso_predicts_test = boosted_lasso.predict(X_test_full[cols_lasso])\n",
    "\n",
    "            # PCA Lasso boosted\n",
    "            # get the components pca returns\n",
    "            comps = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=True)\n",
    "            # get columns to selct the most important components from pca\n",
    "            cols_pca_lasso = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'used_columns', meta_learner=True)\n",
    "            # get fitted pca model\n",
    "            pca = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=True)\n",
    "            #create reduced training data based on pca components\n",
    "            reduced_data = pd.DataFrame(comps)\n",
    "            reduced_data = reduced_data.join(city_training_data.iloc[:,-5:].reset_index(drop = True))\n",
    "            #get trained xgboost\n",
    "            boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier', learner_type = 'meta')\n",
    "\n",
    "            #apply pca to meta_train data\n",
    "            print('meta full: '+str(meta_train_full.shape))\n",
    "            reduced_X_meta_train_full = pd.DataFrame(pca.transform(X_meta_train_full))\n",
    "            print('reduced pca: '+str(reduced_X_meta_train_full.shape))\n",
    "\n",
    "            # apply pca to test data\n",
    "            print('test full: '+str(test_full.shape))\n",
    "            reduced_X_test_full = pd.DataFrame(pca.transform(X_test_full))\n",
    "            print('reduced pca: '+str(reduced_X_test_full.shape))\n",
    "\n",
    "            # make predictions for meta_train data and test data\n",
    "            boosted_pca_lasso_predicts_meta = boosted_pca_lasso.predict(reduced_X_meta_train_full[cols_pca_lasso])\n",
    "            boosted_pca_lasso_predicts_test = boosted_pca_lasso.predict(reduced_X_test_full[cols_pca_lasso])\n",
    "\n",
    "            #store predictions for meta_train in new dataframe and get the mean value of both predictions\n",
    "            city_result_meta = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_meta.loc[:,'boosted_lasso'] = boosted_lasso_predicts_meta\n",
    "            city_result_meta.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_meta\n",
    "            city_result_meta.loc[:, 'mean_model'] = city_result_meta[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            #store predictions for test_data in new dataframe and get the mean value of both predictions\n",
    "            city_result_test = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_test.loc[:,'boosted_lasso'] = boosted_lasso_predicts_test\n",
    "            city_result_test.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_test\n",
    "            city_result_test.loc[:, 'mean_model'] = city_result_test[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            # add prediction to full data sets for meta_training and test\n",
    "            meta_learner_train.loc[:,city] = city_result_meta['mean_model']\n",
    "            meta_learner_test.loc[:,city] = city_result_test['mean_model']\n",
    "\n",
    "    for city in ['bremen', 'hamburg', 'berlin']:\n",
    "\n",
    "        if (city != target_city):\n",
    "\n",
    "            country = 'DE'\n",
    "\n",
    "            city_training_data = train_full[train_full.assigned_city == city]\n",
    "\n",
    "            # Lasso Boosted\n",
    "            cols_lasso = get_best_lasso_model(agg=city_training_data, target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output ='used_columns',meta_learner= True)\n",
    "            boosted_lasso = train_xgboost(city_training_data, target, cols_lasso, 'classifier', learner_type = 'meta')\n",
    "            boosted_lasso_predicts_meta = boosted_lasso.predict(X_meta_train_full[cols_lasso])\n",
    "            boosted_lasso_predicts_test = boosted_lasso.predict(X_test_full[cols_lasso])\n",
    "\n",
    "            # PCA Lasso boosted\n",
    "            comps = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'components', meta_learner=True)\n",
    "            cols_pca_lasso = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'used_columns', meta_learner=True)\n",
    "            pca = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=True)\n",
    "            reduced_data = pd.DataFrame(comps)\n",
    "            reduced_data = reduced_data.join(city_training_data.iloc[:,-5:].reset_index(drop = True))\n",
    "            boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier', learner_type = 'meta')\n",
    "\n",
    "            print('meta full: '+str(meta_train_full.shape))\n",
    "            reduced_X_meta_train_full = pd.DataFrame(pca.transform(X_meta_train_full))\n",
    "            print('reduced pca: '+str(reduced_X_meta_train_full.shape))\n",
    "\n",
    "            print('test full: '+str(test_full.shape))\n",
    "            reduced_X_test_full = pd.DataFrame(pca.transform(X_test_full))\n",
    "            print('reduced pca: '+str(reduced_X_test_full.shape))\n",
    "\n",
    "            boosted_pca_lasso_predicts_meta = boosted_pca_lasso.predict(reduced_X_meta_train_full[cols_pca_lasso])\n",
    "            boosted_pca_lasso_predicts_test = boosted_pca_lasso.predict(reduced_X_test_full[cols_pca_lasso])\n",
    "\n",
    "            city_result_meta = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_meta.loc[:,'boosted_lasso'] = boosted_lasso_predicts_meta\n",
    "            city_result_meta.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_meta\n",
    "            city_result_meta.loc[:, 'mean_model'] = city_result_meta[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            city_result_test = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_test.loc[:,'boosted_lasso'] = boosted_lasso_predicts_test\n",
    "            city_result_test.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_test\n",
    "            city_result_test.loc[:, 'mean_model'] = city_result_test[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            meta_learner_train.loc[:,city] = city_result_meta['mean_model']\n",
    "            meta_learner_test.loc[:,city] = city_result_test['mean_model']   \n",
    "\n",
    "    # add the target column to the meta_train set and test set and add cities back to dataframe    \n",
    "    meta_learner_train.loc[:,target]= y_meta_train_full\n",
    "    meta_learner_test.loc[:,target] = y_test_full\n",
    "    meta_learner_train.loc[:, 'assigned_city'] = meta_train_full.assigned_city\n",
    "    meta_learner_test.loc[:, 'assigned_city'] = test_full.assigned_city\n",
    "\n",
    "\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(meta_learner_train.iloc[:,:-2],meta_learner_train.loc[:,[target]])\n",
    "\n",
    "    #make prediction for test data\n",
    "    y_pred = clf.predict(meta_learner_test.iloc[:,:-2])\n",
    "    naive_pred = [meta_learner_train[[target]].mean().values[0]] * len(meta_learner_test[[target]])\n",
    "\n",
    "    meta_learner_results.loc[target_city, target] = (100-(metrics.mean_squared_error(meta_learner_test[[target]], y_pred)/metrics.mean_squared_error(meta_learner_test[[target]], naive_pred)*100))\n",
    "    meta_learner_r2_score.loc[target_city, target] = metrics.r2_score(meta_learner_test[[target]], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81f65746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data: (1263, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (344, 243)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 133)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 58)\n",
      "shape of training data: (1431, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (176, 243)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 67)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 133)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 58)\n",
      "shape of training data: (746, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (861, 243)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 67)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 66)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 58)\n",
      "shape of training data: (1485, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (122, 243)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 67)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 133)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 43)\n",
      "shape of training data: (1482, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (125, 243)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 67)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 133)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.5\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 53)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 58)\n",
      "shape of training data: (1478, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (129, 243)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 67)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 133)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.5\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 58)\n"
     ]
    }
   ],
   "source": [
    "target = 'foreign_nationals'\n",
    "\n",
    "for target_city in ['marseille', 'lyon', 'paris', 'berlin', 'hamburg', 'bremen']:\n",
    "\n",
    "    train_full = pd.DataFrame(columns = agg_full.columns)\n",
    "    meta_train_full = pd.DataFrame(columns = agg_full.columns)\n",
    "    test_full = pd.DataFrame(columns = agg_full.columns)\n",
    "\n",
    "    # filter data for respective city\n",
    "    for city in ['marseille', 'lyon', 'paris', 'berlin', 'hamburg', 'bremen']:\n",
    "\n",
    "\n",
    "        subset = agg_full[agg_full.assigned_city == city]\n",
    "\n",
    "        if (target_city != city):\n",
    "        # create three subsets - training data, meta_training_data, test_data\n",
    "            train, meta_train = train_test_split(subset, test_size=30, random_state=41)\n",
    "            # append created datasets\n",
    "            train_full = train_full.append(train)\n",
    "            meta_train_full = meta_train_full.append(meta_train)\n",
    "\n",
    "        else:\n",
    "            test_full = subset\n",
    "\n",
    "    #reset index for all three subsets\n",
    "    train_full = train_full.reset_index(drop = True)\n",
    "    meta_train_full = meta_train_full.reset_index(drop = True)\n",
    "    test_full = test_full.reset_index(drop = True)\n",
    "\n",
    "    print('shape of training data: '+str(train_full.shape))\n",
    "    print('shape of meta training data: '+str(meta_train_full.shape))\n",
    "    print('shape of test data: '+str(test_full.shape))\n",
    "\n",
    "    cities = ['marseille', 'lyon', 'paris', 'hamburg', 'bremen', 'berlin', target]\n",
    "    cities.remove(target_city)\n",
    "\n",
    "    meta_learner_train = pd.DataFrame(columns = cities)\n",
    "    meta_learner_test = pd.DataFrame(columns = cities)\n",
    "\n",
    "    # split data in feature and target\n",
    "    X_meta_train_full = meta_train_full.iloc[:,2:-5]\n",
    "    y_meta_train_full = meta_train_full[[target]]\n",
    "\n",
    "    X_test_full = test_full.iloc[:,2:-5]\n",
    "    y_test_full = test_full[[target]]\n",
    "\n",
    "    for city in ['marseille', 'lyon', 'paris']:\n",
    "        country = 'FR'\n",
    "\n",
    "        if(city != target_city):\n",
    "            #filter out data of respective city\n",
    "            city_training_data = train_full[train_full.assigned_city == city]\n",
    "\n",
    "            # Lasso Boosted\n",
    "            #get columns lasso model selects\n",
    "            cols_lasso = get_best_lasso_model(agg=city_training_data, target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output ='used_columns',meta_learner= True)\n",
    "            # get xgboost classifier\n",
    "            boosted_lasso = train_xgboost(city_training_data, target, cols_lasso, 'classifier', learner_type = 'meta')\n",
    "            #make prediction for meta_train data and test data\n",
    "            boosted_lasso_predicts_meta = boosted_lasso.predict(X_meta_train_full[cols_lasso])\n",
    "            boosted_lasso_predicts_test = boosted_lasso.predict(X_test_full[cols_lasso])\n",
    "\n",
    "            # PCA Lasso boosted\n",
    "            # get the components pca returns\n",
    "            comps = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'components', meta_learner=True)\n",
    "            # get columns to selct the most important components from pca\n",
    "            cols_pca_lasso = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'used_columns', meta_learner=True)\n",
    "            # get fitted pca model\n",
    "            pca = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=True)\n",
    "            #create reduced training data based on pca components\n",
    "            reduced_data = pd.DataFrame(comps)\n",
    "            reduced_data = reduced_data.join(city_training_data.iloc[:,-5:].reset_index(drop = True))\n",
    "            #get trained xgboost\n",
    "            boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier', learner_type = 'meta')\n",
    "\n",
    "            #apply pca to meta_train data\n",
    "            print('meta full: '+str(meta_train_full.shape))\n",
    "            reduced_X_meta_train_full = pd.DataFrame(pca.transform(X_meta_train_full))\n",
    "            print('reduced pca: '+str(reduced_X_meta_train_full.shape))\n",
    "\n",
    "            # apply pca to test data\n",
    "            print('test full: '+str(test_full.shape))\n",
    "            reduced_X_test_full = pd.DataFrame(pca.transform(X_test_full))\n",
    "            print('reduced pca: '+str(reduced_X_test_full.shape))\n",
    "\n",
    "            # make predictions for meta_train data and test data\n",
    "            boosted_pca_lasso_predicts_meta = boosted_pca_lasso.predict(reduced_X_meta_train_full[cols_pca_lasso])\n",
    "            boosted_pca_lasso_predicts_test = boosted_pca_lasso.predict(reduced_X_test_full[cols_pca_lasso])\n",
    "\n",
    "            #store predictions for meta_train in new dataframe and get the mean value of both predictions\n",
    "            city_result_meta = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_meta.loc[:,'boosted_lasso'] = boosted_lasso_predicts_meta\n",
    "            city_result_meta.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_meta\n",
    "            city_result_meta.loc[:, 'mean_model'] = city_result_meta[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            #store predictions for test_data in new dataframe and get the mean value of both predictions\n",
    "            city_result_test = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_test.loc[:,'boosted_lasso'] = boosted_lasso_predicts_test\n",
    "            city_result_test.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_test\n",
    "            city_result_test.loc[:, 'mean_model'] = city_result_test[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            # add prediction to full data sets for meta_training and test\n",
    "            meta_learner_train.loc[:,city] = city_result_meta['mean_model']\n",
    "            meta_learner_test.loc[:,city] = city_result_test['mean_model']\n",
    "\n",
    "    for city in ['bremen', 'hamburg', 'berlin']:\n",
    "\n",
    "        if (city != target_city):\n",
    "\n",
    "            country = 'DE'\n",
    "\n",
    "            city_training_data = train_full[train_full.assigned_city == city]\n",
    "\n",
    "            # Lasso Boosted\n",
    "            cols_lasso = get_best_lasso_model(agg=city_training_data, target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output ='used_columns',meta_learner= True)\n",
    "            boosted_lasso = train_xgboost(city_training_data, target, cols_lasso, 'classifier', learner_type = 'meta')\n",
    "            boosted_lasso_predicts_meta = boosted_lasso.predict(X_meta_train_full[cols_lasso])\n",
    "            boosted_lasso_predicts_test = boosted_lasso.predict(X_test_full[cols_lasso])\n",
    "\n",
    "            # PCA Lasso boosted\n",
    "            comps = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'components', meta_learner=True)\n",
    "            cols_pca_lasso = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'used_columns', meta_learner=True)\n",
    "            pca = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=True)\n",
    "            reduced_data = pd.DataFrame(comps)\n",
    "            reduced_data = reduced_data.join(city_training_data.iloc[:,-5:].reset_index(drop = True))\n",
    "            boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier', learner_type = 'meta')\n",
    "\n",
    "            print('meta full: '+str(meta_train_full.shape))\n",
    "            reduced_X_meta_train_full = pd.DataFrame(pca.transform(X_meta_train_full))\n",
    "            print('reduced pca: '+str(reduced_X_meta_train_full.shape))\n",
    "\n",
    "            print('test full: '+str(test_full.shape))\n",
    "            reduced_X_test_full = pd.DataFrame(pca.transform(X_test_full))\n",
    "            print('reduced pca: '+str(reduced_X_test_full.shape))\n",
    "\n",
    "            boosted_pca_lasso_predicts_meta = boosted_pca_lasso.predict(reduced_X_meta_train_full[cols_pca_lasso])\n",
    "            boosted_pca_lasso_predicts_test = boosted_pca_lasso.predict(reduced_X_test_full[cols_pca_lasso])\n",
    "\n",
    "            city_result_meta = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_meta.loc[:,'boosted_lasso'] = boosted_lasso_predicts_meta\n",
    "            city_result_meta.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_meta\n",
    "            city_result_meta.loc[:, 'mean_model'] = city_result_meta[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            city_result_test = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_test.loc[:,'boosted_lasso'] = boosted_lasso_predicts_test\n",
    "            city_result_test.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_test\n",
    "            city_result_test.loc[:, 'mean_model'] = city_result_test[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            meta_learner_train.loc[:,city] = city_result_meta['mean_model']\n",
    "            meta_learner_test.loc[:,city] = city_result_test['mean_model']   \n",
    "\n",
    "    # add the target column to the meta_train set and test set and add city column back to dataframe    \n",
    "    meta_learner_train.loc[:,target]= y_meta_train_full\n",
    "    meta_learner_test.loc[:,target] = y_test_full\n",
    "    meta_learner_train.loc[:, 'assigned_city'] = meta_train_full.assigned_city\n",
    "    meta_learner_test.loc[:, 'assigned_city'] = test_full.assigned_city\n",
    "\n",
    "    #train meta learner\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(meta_learner_train.iloc[:,:-2],meta_learner_train.loc[:,[target]])\n",
    "\n",
    "    #make prediction for test data\n",
    "    y_pred = clf.predict(meta_learner_test.iloc[:,:-2])\n",
    "    naive_pred = [meta_learner_train[[target]].mean().values[0]] * len(meta_learner_test[[target]])\n",
    "\n",
    "    meta_learner_results.loc[target_city, target] = (100-(metrics.mean_squared_error(meta_learner_test[[target]], y_pred)/metrics.mean_squared_error(meta_learner_test[[target]], naive_pred)*100))\n",
    "    meta_learner_r2_score.loc[target_city, target] = metrics.r2_score(meta_learner_test[[target]], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b83e6d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data: (1263, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (344, 243)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 133)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (344, 243)\n",
      "reduced pca: (344, 58)\n",
      "shape of training data: (1431, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (176, 243)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 67)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 133)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (176, 243)\n",
      "reduced pca: (176, 58)\n",
      "shape of training data: (746, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (861, 243)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 67)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 66)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (861, 243)\n",
      "reduced pca: (861, 58)\n",
      "shape of training data: (1485, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (122, 243)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 67)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 133)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 53)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (122, 243)\n",
      "reduced pca: (122, 43)\n",
      "shape of training data: (1482, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (125, 243)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 67)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 133)\n",
      "0.1\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "shape before pca: (99, 236)\n",
      "number of pca components: 53\n",
      "shape after pca: (99, 53)\n",
      "0.2\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 53)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 53)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (125, 243)\n",
      "reduced pca: (125, 58)\n",
      "shape of training data: (1478, 243)\n",
      "shape of meta training data: (150, 243)\n",
      "shape of test data: (129, 243)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "shape before pca: (314, 236)\n",
      "number of pca components: 67\n",
      "shape after pca: (314, 67)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 67)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 67)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "shape before pca: (146, 236)\n",
      "number of pca components: 66\n",
      "shape after pca: (146, 66)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 66)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 66)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "shape before pca: (831, 236)\n",
      "number of pca components: 133\n",
      "shape after pca: (831, 133)\n",
      "0.01\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 133)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 133)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "shape before pca: (95, 236)\n",
      "number of pca components: 43\n",
      "shape after pca: (95, 43)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 43)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 43)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "shape before pca: (92, 236)\n",
      "number of pca components: 58\n",
      "shape after pca: (92, 58)\n",
      "0.1\n",
      "meta full: (150, 243)\n",
      "reduced pca: (150, 58)\n",
      "test full: (129, 243)\n",
      "reduced pca: (129, 58)\n"
     ]
    }
   ],
   "source": [
    "target = 'income_levels'\n",
    "\n",
    "for target_city in ['marseille', 'lyon', 'paris', 'berlin', 'hamburg', 'bremen']:\n",
    "\n",
    "    train_full = pd.DataFrame(columns = agg_full.columns)\n",
    "    meta_train_full = pd.DataFrame(columns = agg_full.columns)\n",
    "    test_full = pd.DataFrame(columns = agg_full.columns)\n",
    "\n",
    "    # filter data for respective city\n",
    "    for city in ['marseille', 'lyon', 'paris', 'berlin', 'hamburg', 'bremen']:\n",
    "\n",
    "\n",
    "        subset = agg_full[agg_full.assigned_city == city]\n",
    "\n",
    "        if (target_city != city):\n",
    "        # create three subsets - training data, meta_training_data, test_data\n",
    "            train, meta_train = train_test_split(subset, test_size=30, random_state=41)\n",
    "            # append created datasets\n",
    "            train_full = train_full.append(train)\n",
    "            meta_train_full = meta_train_full.append(meta_train)\n",
    "\n",
    "        else:\n",
    "            test_full = subset\n",
    "\n",
    "    #reset index for all three subsets\n",
    "    train_full = train_full.reset_index(drop = True)\n",
    "    meta_train_full = meta_train_full.reset_index(drop = True)\n",
    "    test_full = test_full.reset_index(drop = True)\n",
    "\n",
    "    print('shape of training data: '+str(train_full.shape))\n",
    "    print('shape of meta training data: '+str(meta_train_full.shape))\n",
    "    print('shape of test data: '+str(test_full.shape))\n",
    "\n",
    "    cities = ['marseille', 'lyon', 'paris', 'hamburg', 'bremen', 'berlin', target]\n",
    "    cities.remove(target_city)\n",
    "\n",
    "    meta_learner_train = pd.DataFrame(columns = cities)\n",
    "    meta_learner_test = pd.DataFrame(columns = cities)\n",
    "\n",
    "    # split data in feature and target\n",
    "    X_meta_train_full = meta_train_full.iloc[:,2:-5]\n",
    "    y_meta_train_full = meta_train_full[[target]]\n",
    "\n",
    "    X_test_full = test_full.iloc[:,2:-5]\n",
    "    y_test_full = test_full[[target]]\n",
    "\n",
    "    for city in ['marseille', 'lyon', 'paris']:\n",
    "        country = 'FR'\n",
    "\n",
    "        if(city != target_city):\n",
    "            #filter out data of respective city\n",
    "            city_training_data = train_full[train_full.assigned_city == city]\n",
    "\n",
    "            # Lasso Boosted\n",
    "            #get columns lasso model selects\n",
    "            cols_lasso = get_best_lasso_model(agg=city_training_data, target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output ='used_columns',meta_learner= True)\n",
    "            # get xgboost classifier\n",
    "            boosted_lasso = train_xgboost(city_training_data, target, cols_lasso, 'classifier', learner_type = 'meta')\n",
    "            #make prediction for meta_train data and test data\n",
    "            boosted_lasso_predicts_meta = boosted_lasso.predict(X_meta_train_full[cols_lasso])\n",
    "            boosted_lasso_predicts_test = boosted_lasso.predict(X_test_full[cols_lasso])\n",
    "\n",
    "            # PCA Lasso boosted\n",
    "            # get the components pca returns\n",
    "            comps = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'components', meta_learner=True)\n",
    "            # get columns to selct the most important components from pca\n",
    "            cols_pca_lasso = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'used_columns', meta_learner=True)\n",
    "            # get fitted pca model\n",
    "            pca = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=True)\n",
    "            #create reduced training data based on pca components\n",
    "            reduced_data = pd.DataFrame(comps)\n",
    "            reduced_data = reduced_data.join(city_training_data.iloc[:,-5:].reset_index(drop = True))\n",
    "            #get trained xgboost\n",
    "            boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier', learner_type = 'meta')\n",
    "\n",
    "            #apply pca to meta_train data\n",
    "            print('meta full: '+str(meta_train_full.shape))\n",
    "            reduced_X_meta_train_full = pd.DataFrame(pca.transform(X_meta_train_full))\n",
    "            print('reduced pca: '+str(reduced_X_meta_train_full.shape))\n",
    "\n",
    "            # apply pca to test data\n",
    "            print('test full: '+str(test_full.shape))\n",
    "            reduced_X_test_full = pd.DataFrame(pca.transform(X_test_full))\n",
    "            print('reduced pca: '+str(reduced_X_test_full.shape))\n",
    "\n",
    "            # make predictions for meta_train data and test data\n",
    "            boosted_pca_lasso_predicts_meta = boosted_pca_lasso.predict(reduced_X_meta_train_full[cols_pca_lasso])\n",
    "            boosted_pca_lasso_predicts_test = boosted_pca_lasso.predict(reduced_X_test_full[cols_pca_lasso])\n",
    "\n",
    "            #store predictions for meta_train in new dataframe and get the mean value of both predictions\n",
    "            city_result_meta = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_meta.loc[:,'boosted_lasso'] = boosted_lasso_predicts_meta\n",
    "            city_result_meta.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_meta\n",
    "            city_result_meta.loc[:, 'mean_model'] = city_result_meta[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            #store predictions for test_data in new dataframe and get the mean value of both predictions\n",
    "            city_result_test = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_test.loc[:,'boosted_lasso'] = boosted_lasso_predicts_test\n",
    "            city_result_test.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_test\n",
    "            city_result_test.loc[:, 'mean_model'] = city_result_test[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            # add prediction to full data sets for meta_training and test\n",
    "            meta_learner_train.loc[:,city] = city_result_meta['mean_model']\n",
    "            meta_learner_test.loc[:,city] = city_result_test['mean_model']\n",
    "\n",
    "    for city in ['bremen', 'hamburg', 'berlin']:\n",
    "\n",
    "        if (city != target_city):\n",
    "\n",
    "            country = 'DE'\n",
    "\n",
    "            city_training_data = train_full[train_full.assigned_city == city]\n",
    "\n",
    "            # Lasso Boosted\n",
    "            cols_lasso = get_best_lasso_model(agg=city_training_data, target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output ='used_columns',meta_learner= True)\n",
    "            boosted_lasso = train_xgboost(city_training_data, target, cols_lasso, 'classifier', learner_type = 'meta')\n",
    "            boosted_lasso_predicts_meta = boosted_lasso.predict(X_meta_train_full[cols_lasso])\n",
    "            boosted_lasso_predicts_test = boosted_lasso.predict(X_test_full[cols_lasso])\n",
    "\n",
    "            # PCA Lasso boosted\n",
    "            comps = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'components', meta_learner=True)\n",
    "            cols_pca_lasso = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015,  density_type='count', radius = 1000, output = 'used_columns', meta_learner=True)\n",
    "            pca = get_best_pca_lasso_model(agg=city_training_data,target=target, city=city, country=country, socio_year=2015, density_type='count', radius = 1000, output = 'pca_classifier', meta_learner=True)\n",
    "            reduced_data = pd.DataFrame(comps)\n",
    "            reduced_data = reduced_data.join(city_training_data.iloc[:,-5:].reset_index(drop = True))\n",
    "            boosted_pca_lasso = train_xgboost(reduced_data, target, cols_pca_lasso, 'classifier', learner_type = 'meta')\n",
    "\n",
    "            print('meta full: '+str(meta_train_full.shape))\n",
    "            reduced_X_meta_train_full = pd.DataFrame(pca.transform(X_meta_train_full))\n",
    "            print('reduced pca: '+str(reduced_X_meta_train_full.shape))\n",
    "\n",
    "            print('test full: '+str(test_full.shape))\n",
    "            reduced_X_test_full = pd.DataFrame(pca.transform(X_test_full))\n",
    "            print('reduced pca: '+str(reduced_X_test_full.shape))\n",
    "\n",
    "            boosted_pca_lasso_predicts_meta = boosted_pca_lasso.predict(reduced_X_meta_train_full[cols_pca_lasso])\n",
    "            boosted_pca_lasso_predicts_test = boosted_pca_lasso.predict(reduced_X_test_full[cols_pca_lasso])\n",
    "\n",
    "            city_result_meta = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_meta.loc[:,'boosted_lasso'] = boosted_lasso_predicts_meta\n",
    "            city_result_meta.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_meta\n",
    "            city_result_meta.loc[:, 'mean_model'] = city_result_meta[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            city_result_test = pd.DataFrame(columns = ['boosted_lasso', 'boosted_pca_lasso'])\n",
    "            city_result_test.loc[:,'boosted_lasso'] = boosted_lasso_predicts_test\n",
    "            city_result_test.loc[:,'boosted_pca_lasso'] = boosted_pca_lasso_predicts_test\n",
    "            city_result_test.loc[:, 'mean_model'] = city_result_test[['boosted_lasso', 'boosted_pca_lasso']].mean(axis = 1)\n",
    "\n",
    "            meta_learner_train.loc[:,city] = city_result_meta['mean_model']\n",
    "            meta_learner_test.loc[:,city] = city_result_test['mean_model']   \n",
    "\n",
    "    # add the target column to the meta_train set and test set and add cities back to dataframe    \n",
    "    meta_learner_train.loc[:,target]= y_meta_train_full\n",
    "    meta_learner_test.loc[:,target] = y_test_full\n",
    "    meta_learner_train.loc[:, 'assigned_city'] = meta_train_full.assigned_city\n",
    "    meta_learner_test.loc[:, 'assigned_city'] = test_full.assigned_city\n",
    "\n",
    "    #train meta learner\n",
    "    clf = LinearRegression()\n",
    "    clf.fit(meta_learner_train.iloc[:,:-2],meta_learner_train.loc[:,[target]])\n",
    "\n",
    "    #make prediction for test data\n",
    "    y_pred = clf.predict(meta_learner_test.iloc[:,:-2])\n",
    "    naive_pred = [meta_learner_train[[target]].mean().values[0]] * len(meta_learner_test[[target]])\n",
    "\n",
    "    meta_learner_results.loc[target_city, target] = (100-(metrics.mean_squared_error(meta_learner_test[[target]], y_pred)/metrics.mean_squared_error(meta_learner_test[[target]], naive_pred)*100))\n",
    "    meta_learner_r2_score.loc[target_city, target] = metrics.r2_score(meta_learner_test[[target]], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b983ca25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>foreign_nationals</th>\n",
       "      <th>income_levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>0.115469</td>\n",
       "      <td>0.161379</td>\n",
       "      <td>0.09823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>-0.173374</td>\n",
       "      <td>-0.152299</td>\n",
       "      <td>-0.095444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>0.148987</td>\n",
       "      <td>-0.111399</td>\n",
       "      <td>0.134582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>0.198991</td>\n",
       "      <td>-0.077528</td>\n",
       "      <td>0.126903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>0.070679</td>\n",
       "      <td>0.12844</td>\n",
       "      <td>0.06697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>0.076006</td>\n",
       "      <td>-0.04257</td>\n",
       "      <td>0.139417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.072793</td>\n",
       "      <td>-0.015663</td>\n",
       "      <td>0.078443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unemployment_rate foreign_nationals income_levels\n",
       "marseille          0.115469          0.161379       0.09823\n",
       "lyon              -0.173374         -0.152299     -0.095444\n",
       "paris              0.148987         -0.111399      0.134582\n",
       "berlin             0.198991         -0.077528      0.126903\n",
       "hamburg            0.070679           0.12844       0.06697\n",
       "bremen             0.076006          -0.04257      0.139417\n",
       "mean               0.072793         -0.015663      0.078443"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_learner_r2_score.loc['mean'] = meta_learner_r2_score.mean()\n",
    "meta_learner_r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac821a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>foreign_nationals</th>\n",
       "      <th>income_levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>marseille</th>\n",
       "      <td>12.189508</td>\n",
       "      <td>17.691429</td>\n",
       "      <td>10.959759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyon</th>\n",
       "      <td>-16.79867</td>\n",
       "      <td>-14.959591</td>\n",
       "      <td>-9.343855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paris</th>\n",
       "      <td>15.476607</td>\n",
       "      <td>-9.775911</td>\n",
       "      <td>13.609479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berlin</th>\n",
       "      <td>31.147518</td>\n",
       "      <td>-7.203995</td>\n",
       "      <td>13.143534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamburg</th>\n",
       "      <td>20.359341</td>\n",
       "      <td>12.85219</td>\n",
       "      <td>10.349731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bremen</th>\n",
       "      <td>11.396219</td>\n",
       "      <td>4.625742</td>\n",
       "      <td>18.145471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unemployment_rate foreign_nationals income_levels\n",
       "marseille         12.189508         17.691429     10.959759\n",
       "lyon              -16.79867        -14.959591     -9.343855\n",
       "paris             15.476607         -9.775911     13.609479\n",
       "berlin            31.147518         -7.203995     13.143534\n",
       "hamburg           20.359341          12.85219     10.349731\n",
       "bremen            11.396219          4.625742     18.145471"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_learner_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
